
<body>
  <div class="container">
<link rel="stylesheet" href="style.css">



<h1 id="applications-of-ai-in-infosec">Applications of AI in InfoSec</h1>
<h2 id="introduction">Introduction</h2>
<p>Following the <a href="https://academy.hackthebox.com/module/details/290">Fundamentals of AI</a> module, this module takes a more practical approach to applying <code>machine learning</code> techniques. Instead of focusing solely on theory, you will now engage in hands-on activities that involve building and evaluating real models. Throughout this process, you will gain experience with the end-to-end workflow of <code>AI</code> development, from exploring datasets to training and testing models.</p>
<p>You will construct three distinct <code>AI</code> models in this module:</p>
<ol>
<li>A <code>Spam Classifier</code> to determine whether an SMS message is <code>spam</code> or not.</li>
<li>A <code>Network Anomaly Detection Model</code> designed to identify abnormal or potentially malicious network traffic.</li>
<li>A <code>Malware Classifier</code> using <code>byteplots</code>, which are visual representations of binary data.</li>
</ol>
<p>Throughout the module, you will encounter <code>python code blocks</code> that guide you step-by-step through the model-building process.</p>
<p>You will learn more about <code>Jupyter</code> later in this module, but for now, understand that you can copy and paste these code snippets into a <code>Jupyter</code> notebook to execute them in sequence, either in the playground VM, or your environment.</p>
<p>You can train most of these models in your own environment. For a decent experience, you will need at least 4GB of RAM and at least 4 CPU cores.</p>
<p>Note: Throughout this module, all sections marked as interactive contain code blocks for you to follow along. Not all interactive sections contain separate exercises.</p>
<hr>
<h2 id="environment-setup">Environment Setup</h2>
<hr>
<p>Setting up a proper environment is essential before diving into the exciting world of AI. This module offers two paths for an enviroment.</p>
<h3 id="the-playground">The Playground</h3>
<p>The first is The Playground. Because we acknowledge that not everyone will have the computer resources required to build the models in this module, we have provided a Virtual Playground Environment for you to use if you absolutely need it.</p>
<p>Because this is separate from PwnBox, there are specific sections where you can spawn this VM. You can connect to it using your HTB VPN profile or PwnBox. The VM exposes Jupyter for you to work in, which will be covered in the next section, but you can access it on <code>http://&lt;VM-IP&gt;:8888</code>. You can spawn the VM and extend instance time if needed at the bottom of this section or any of the <code>Model Evaluation</code> sections in the module.</p>
<p><i class="fa-arrow-circle-left">:arrow-circle-left:</i> <i class="fa-arrow-right">:arrow-right:</i> <i class="fa-redo">:redo:</i> <i class="fa-home">:home:</i><i class="fa-bars">:bars:</i><img src="https://academy.hackthebox.com/storage/modules/292/jupyter.png" alt="JupyterLab interface showing a file browser with a &#39;data&#39; folder and an open terminal with a command prompt."></p>
<p>Note: While the Playground environment is sufficient to follow along with everything discussed in this module, it lacks in performance to provide an environment that encourages experimentation. Therefore, we recommend setting up an environment on your own system, provided you have sufficiently powerful hardware. This will result in shorter training times and enable experimentation with different parameters, resulting in a more enjoyable way to work through the module and improve your understanding of the performance impact of different training parameters.</p>
<p>The second is to set up an environment on your own system, which you can do by following the rest of this section. For this module you will need at least 4GB of RAM. In a majority of cases, your own environment will provide faster training times than the playground VM.</p>
<hr>
<h3 id="miniconda">Miniconda</h3>
<p><code>Miniconda</code> is a minimal installer for the <code>Anaconda</code> distribution of the <code>Python</code> programming language. It provides the <code>conda</code> package manager and a core Python environment without automatically installing the full suite of data science libraries available in <code>Anaconda</code>. Users can selectively install additional packages, creating a customized environment that aligns with their specific needs.</p>
<p>Both <code>Miniconda</code> and <code>Anaconda</code> rely on the <code>conda</code> package manager, allowing for simplified installation, updating, and management of Python packages and their dependencies. In essence, <code>Miniconda</code> offers a lighter starting point, while <code>Anaconda</code> comes pre-loaded with a broader range of commonly used data science tools.</p>
<h4 id="why-miniconda-">Why Miniconda?</h4>
<p>You might wonder why we use <code>Miniconda</code> instead of a standard <code>Python</code> installation. Here are a few compelling reasons:</p>
<ul>
<li><code>Performance:</code> <code>Miniconda</code> often performs data science and machine learning tasks better due to optimized packages and libraries.</li>
<li><code>Package Management:</code> The <code>Conda</code> package manager simplifies package installation and management, ensuring compatibility and resolving dependencies. This is particularly crucial in deep learning, where projects often rely on a complex web of interconnected libraries.</li>
<li><code>Environment Isolation:</code> <code>Miniconda</code> allows you to create isolated environments for different projects. This prevents conflicts between packages and ensures each project has its dedicated dependencies.</li>
</ul>
<p>By using <code>Miniconda</code>, you&#39;ll streamline your workflow, avoid compatibility issues, and ensure that your deep learning environment is optimized for performance and efficiency.</p>
<h3 id="installing-miniconda">Installing Miniconda</h3>
<h4 id="windows">Windows</h4>
<p>While the traditional installer works well, we can streamline the process on Windows using <code>Scoop</code>, a command-line installer for Windows. <code>Scoop</code> simplifies the installation and management of various applications, including <code>Miniconda</code>.</p>
<p>First, install <code>Scoop</code>. Open PowerShell and run:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-powershell-session"><span class="hljs-symbol">C:</span>\&gt; <span class="hljs-keyword">Set</span>-ExecutionPolicy RemoteSigned -scope CurrentUser <span class="hljs-meta"># Allow scripts to run</span>
<span class="hljs-symbol">C:</span>\&gt; irm get.scoop.sh | iex
</code></pre>
<p>Next, add the <code>extras</code> bucket, which contains <code>Miniconda</code>:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-powershell-session">C:\&gt; <span class="hljs-keyword">scoop </span><span class="hljs-keyword">bucket </span><span class="hljs-keyword">add </span><span class="hljs-keyword">extras</span>
</code></pre>
<p>Finally, install <code>Miniconda</code> with:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-powershell-session">C:\&gt; <span class="hljs-keyword">scoop </span><span class="hljs-keyword">install </span>miniconda3
</code></pre>
<p>This command installs the latest Python 3 version of <code>Miniconda</code>.</p>
<p>To verify the installation, close and reopen PowerShell. Type <code>conda --version</code> to check if <code>Miniconda</code> is installed correctly.</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-powershell-session"><span class="hljs-selector-tag">C</span>:\&gt; <span class="hljs-selector-tag">conda</span> <span class="hljs-selector-tag">--version</span>

<span class="hljs-selector-tag">conda</span> 24<span class="hljs-selector-class">.9</span><span class="hljs-selector-class">.2</span>
</code></pre>
<h4 id="macos">MacOS</h4>
<p>Homebrew, a popular package manager for macOS, simplifies software installation and keeps it up-to-date. It also provides a convenient way for macOS users to install Miniconda.</p>
<p>If you don&#39;t have <code>Homebrew</code>, install it first by pasting the following command in your terminal:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session">root<span class="hljs-meta">@htb</span>[<span class="hljs-regexp">/htb]$ /</span>bin<span class="hljs-regexp">/bash -c "$(curl -fsSL https:/</span><span class="hljs-regexp">/raw.githubusercontent.com/</span>Homebrew<span class="hljs-regexp">/install/</span>HEAD/install.sh)<span class="hljs-string">"</span>
</code></pre>
<p>Once <code>Homebrew</code> is set up, you can install <code>Miniconda</code> with this simple command:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ brew install --cask miniconda
</code></pre>
<p>This command installs the latest version of <code>Miniconda</code> with Python 3.</p>
<p>To verify the installation, close and reopen your terminal. Type <code>conda --version</code> to confirm that <code>Miniconda</code> is installed correctly.</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ conda --version

conda <span class="hljs-number">24.9</span>.<span class="hljs-number">2</span>
</code></pre>
<h4 id="linux">Linux</h4>
<p>Miniconda provides a straightforward installation process that relies not solely on a distribution’s package manager. You can obtain the latest Miniconda installer directly from the official repository, run it silently, and then load the conda environment for your user shell. This approach ensures that conda commands and environments are readily available without manual configuration.</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session">root<span class="hljs-meta">@htb</span>[<span class="hljs-regexp">/htb]$ wget https:/</span><span class="hljs-regexp">/repo.anaconda.com/</span>miniconda/Miniconda3-latest-Linux-x86_64.sh
root<span class="hljs-meta">@htb</span>[/htb]$ chmod +x Miniconda3-latest-Linux-x86_64.sh
root<span class="hljs-meta">@htb</span>[<span class="hljs-regexp">/htb]$ ./</span>Miniconda3-latest-Linux-x86_64.sh -b -u
root<span class="hljs-meta">@htb</span>[<span class="hljs-regexp">/htb]$ eval "$(/</span>home<span class="hljs-regexp">/$USER/</span>miniconda3<span class="hljs-regexp">/bin/</span>conda shell.$(ps -p $$ -o comm=) hook)<span class="hljs-string">"</span>
</code></pre>
<p>Confirm that Miniconda is installed correctly by running:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ conda --version

conda <span class="hljs-number">24.9</span>.<span class="hljs-number">2</span>
</code></pre>
<h3 id="init">Init</h3>
<p>The <code>init</code> command configures your shell to recognize and utilize <code>conda</code>. This step is essential for:</p>
<ul>
<li><code>Activating environments:</code> Allows you to use <code>conda activate</code> to switch between environments.</li>
<li><code>Using conda commands:</code> Ensures that <code>conda</code> commands are available in your shell.</li>
</ul>
<p>To initialize <code>conda</code> for your shell, run the following command after installing <code>Miniconda</code>:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ conda init
</code></pre>
<p>This command will modify your shell configuration files (e.g., <code>.bashrc</code> or <code>.zshrc</code>) to include the necessary <code>conda</code> settings. You might need to close and reopen your terminal for the changes to take effect.</p>
<p>Finally, run these two commands to complete the <code>init</code> process</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session">root@htb[/htb]$ conda config --<span class="hljs-keyword">add</span><span class="bash"> channels defaults
</span>root@htb[/htb]$ conda config --<span class="hljs-keyword">add</span><span class="bash"> channels conda-forge
</span>root@htb[/htb]$ conda config --<span class="hljs-keyword">add</span><span class="bash"> channels nvidia <span class="hljs-comment"># only needed if you are on a PC that has a nvidia gpu</span>
</span>root@htb[/htb]$ conda config --<span class="hljs-keyword">add</span><span class="bash"> channels pytorch
</span>root@htb[/htb]$ conda config --set channel_priority strict
</code></pre>
<h3 id="deactivating-base">Deactivating Base</h3>
<p>After installing <code>Miniconda</code>, you&#39;ll notice that the <code>base</code> environment is activated by default every time you open a new terminal. This is indicated by the <code>(base)</code> prefix on your path.</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session">(<span class="hljs-keyword">base) </span>$
</code></pre>
<p>While this can be useful, it&#39;s often preferable to start with a clean slate and activate environments only when needed. Personally, I wouldn&#39;t say I like seeing the <code>(base)</code> prefix all the time, either.</p>
<p>To prevent the <code>base</code> environment from activating automatically, you can use the following command:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session">root<span class="hljs-meta">@htb</span>[/htb]$ conda config --<span class="hljs-keyword">set</span> auto_activate_base <span class="hljs-keyword">false</span>
</code></pre>
<p>This command modifies the <code>condarc</code> configuration file and disables the automatic activation of the <code>base</code> environment.</p>
<p>When you open a new terminal, you won&#39;t see the <code>(base)</code> prefix in your prompt anymore.</p>
<h3 id="managing-virtual-environments">Managing Virtual Environments</h3>
<p>In software development, managing dependencies can quickly become a complex task, especially when working on multiple projects with different library requirements.</p>
<p>This is where <code>virtual environments</code> come into play. A virtual environment is an isolated space where you can install packages and dependencies specific to a particular project, without interfering with other projects or your system&#39;s global Python installation.</p>
<p>They are critical for AI tasks for a few reasons:</p>
<ul>
<li><code>Dependency Isolation:</code> Each project can have its own set of dependencies, even if they conflict with those of other projects.</li>
<li><code>Clean Project Structure:</code> Keeps your project directory clean and organized by containing all dependencies within the environment.</li>
<li><code>Reproducibility:</code> Ensures that your project can be easily reproduced on different systems with the same dependencies.</li>
<li><code>System Stability:</code> Prevents conflicts with your global Python installation and avoids breaking other projects.</li>
</ul>
<p><code>conda</code> provides a simple way to create virtual environments. For example, to create a new environment named <code>ai</code> with Python 3.11, use the following command:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ conda create -n ai python=<span class="hljs-number">3.11</span>
</code></pre>
<p>This will create a virtual environment, <code>ai</code>, which can then be used to contain all ai-related packages.</p>
<h4 id="activating-the-environment">Activating the Environment</h4>
<p>To activate the <code>myenv</code> environment, use:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ conda activate ai
</code></pre>
<p>You&#39;ll notice that your terminal prompt now includes the environment name in parentheses <code>(ai)</code>, indicating that the environment is active. Any packages you install using <code>conda</code> or <code>pip</code> will now be installed within this environment.</p>
<p>To deactivate the environment, use:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ conda deactivate
</code></pre>
<p>The environment name will disappear from your prompt, and you&#39;ll be back to your base Python environment.</p>
<h3 id="essential-setup">Essential Setup</h3>
<p>With your <code>Miniconda</code> environment set up, you can install the essential packages for your AI journey. These packages generally cover what will be needed in this module.</p>
<p>While <code>conda</code> provides a broad range of packages through its curated channels, it may not include every tool you require. In such cases, you can still use <code>pip</code> within the <code>conda</code> environment. This approach ensures you can install any additional packages that <code>conda</code> does not cover.</p>
<p>Use the <code>conda install</code> command to install the following core packages:</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session">root@htb[/htb]$ conda <span class="hljs-keyword">install</span> -y numpy scipy pandas scikit-learn matplotlib seaborn transformers datasets tokenizers accelerate <span class="hljs-keyword">evaluate</span> optimum huggingface_hub nltk category_encoders
root@htb[/htb]$ conda <span class="hljs-keyword">install</span> -y pytorch torchvision torchaudio pytorch-cuda=<span class="hljs-number">12.4</span> -c pytorch -c nvidia
root@htb[/htb]$ pip <span class="hljs-keyword">install</span> requests requests_toolbelt
</code></pre>
<h3 id="updates">Updates</h3>
<p><code>conda</code> provides a method to keep conda-managed packages up to date. Running the following command updates all conda-installed packages within the <code>(ai)</code> environment, but it does not update packages installed with <code>pip</code>. Any pip-installed packages must be managed separately, and mixing <code>pip</code> and <code>conda</code> installations may increase the risk of dependency conflicts.</p>
<p>&#x20; Environment Setup</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ conda update --all
</code></pre>
<hr>
<h2 id="jupyterlab">JupyterLab</h2>
<hr>
<p><code>JupyterLab</code> is an interactive development environment that provides web-based coding, data, and visualization interfaces. Due to its flexibility and interactive features, it&#39;s a popular choice for data scientists and machine learning practitioners.</p>
<h3 id="why-jupyterlab-">Why JupyterLab?</h3>
<ul>
<li><code>Interactive Environment</code>: <code>JupyterLab</code> allows running code in individual cells, facilitating experimentation and iterative development.</li>
<li><code>Data Exploration and Visualization</code>: It integrates seamlessly with libraries like <code>matplotlib</code> and <code>seaborn</code> for creating visualizations and exploring data.</li>
<li><code>Documentation and Sharing</code>: <code>JupyterLab</code> supports markdown and LaTeX for creating rich documentation and sharing code with others.</li>
</ul>
<p><code>JupyterLab</code> can be easily installed using <code>conda</code>, if it isn&#39;t already installed:</p>
<p>&#x20; JupyterLab</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ conda install -y jupyter jupyterlab notebook ipykernel
</code></pre>
<p>Make sure you are running the command from within your ai environment.</p>
<p>To start <code>JupyterLab</code>, simply run:</p>
<p>&#x20; JupyterLab</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ jupyter lab
</code></pre>
<p>This will open a new tab in your web browser with the <code>JupyterLab</code> interface.</p>
<h3 id="using-jupyterlab">Using JupyterLab</h3>
<p><img src="https://academy.hackthebox.com/storage/modules/292/jupyter_dark.png" alt="JupyterLab launcher with folders and Python 3 options for Notebook and Console."></p>
<p><code>JupyterLab</code>&#39;s primary component is the notebook, which allows combining code, text, and visualizations in a single document. Notebooks are organized into cells, where each cell can contain either code or markdown text.</p>
<ul>
<li><code>Code cells</code>: Execute code in various languages (Python, R, Julia).</li>
<li><code>Markdown cells</code>: Create formatted text, equations, and images using markdown syntax.</li>
<li><code>Raw cells</code>: Untyped raw text.</li>
</ul>
<p>Click the &quot;Python 3&quot; icon under the &quot;Notebook&quot; section in the Launcher interface to create a new notebook. This will open a notebook with a single empty code cell.</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/jupyter_new.png" alt="JupyterLab interface with a file browser and an open, untitled notebook."></p>
<p>Type your Python code into the code cell and press <code>Shift + Enter</code> to execute it. For example:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">"Hello, JupyterLab!"</span>)</span></span>
</code></pre>
<p>The output of the code will appear below the cell.</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/jupyter_hello_output.png" alt="JupyterLab interface with a file browser and an open notebook displaying Python code output: &#39;Hello, JupyterLab!&#39;."></p>
<p><code>Jupyter</code> notebooks use a <code>stateful</code> environment, which means that variables, functions, and imports defined in one cell remain available to all later cells. Once you execute a cell, any changes it makes to the environment, such as assigning new variables or redefining functions, persist as long as the kernel is running. This differs from a <code>stateless</code> model, where each code execution is isolated and does not retain information from previous executions.</p>
<p>Being aware of the <code>stateful</code> nature of a notebook is important. For example, if you execute cells out of order, you might observe unexpected results due to previously defined or modified variables. Similarly, re-importing modules or updating variable values affects subsequent cell executions, but not those that were previously run.</p>
<p>Say you have a cell that does this:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-attr">x</span> = <span class="hljs-number">1</span>
</code></pre>
<p>then in a later cell you might have:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">print</span>(x)  # <span class="hljs-keyword">This</span> will <span class="hljs-keyword">print</span> <span class="hljs-string">'1'</span> because <span class="hljs-string">'x'</span> was defined previously.
</code></pre>
<p>If you change the first cell to:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-attr">x</span> = <span class="hljs-number">2</span>
</code></pre>
<p>and re-run it before running the <code>print(x)</code> cell, the value of <code>x</code> in the environment becomes <code>2</code>, so the output will now be different when you run the print cell.</p>
<p>Click the &quot;+&quot; button in the toolbar to add new cells. You can choose between code cells and markdown cells using the Dropdown on the toolbar. Markdown cells allow you to write formatted text and include headings, lists, and links.</p>
<p><code>JupyterLab</code> integrates with libraries like <code>pandas</code>, <code>matplotlib</code>, and <code>seaborn</code> for data exploration and visualization. Here&#39;s an example of loading a dataset with <code>pandas</code> and creating a simple plot:</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/jupyter_simple_plot.png" alt="JupyterLab interface showing Python code for creating a DataFrame and scatter plot, with a displayed plot of random data points."></p>
<p>Code: python</p>
<pre><code class="lang-python">import pandas as pd
import matplotlib.pyplot as plt
import numpy as <span class="hljs-built_in">np</span>

# Create a sample DataFrame
data = pd.DataFrame({
    <span class="hljs-string">"column1"</span>: <span class="hljs-built_in">np</span>.<span class="hljs-built_in">random</span>.rand(<span class="hljs-number">50</span>),  # <span class="hljs-number">50</span> <span class="hljs-built_in">random</span> <span class="hljs-built_in">values</span> <span class="hljs-keyword">for</span> column1
    <span class="hljs-string">"column2"</span>: <span class="hljs-built_in">np</span>.<span class="hljs-built_in">random</span>.rand(<span class="hljs-number">50</span>) * <span class="hljs-number">10</span>  # <span class="hljs-number">50</span> <span class="hljs-built_in">random</span> <span class="hljs-built_in">values</span> (multiplied by <span class="hljs-number">10</span>) <span class="hljs-keyword">for</span> column2
})

# Display the <span class="hljs-built_in">first</span> few rows
<span class="hljs-built_in">print</span>(data.head())

# Create a scatter plot
plt.scatter(data[<span class="hljs-string">"column1"</span>], data[<span class="hljs-string">"column2"</span>])
plt.<span class="hljs-built_in">xlabel</span>(<span class="hljs-string">"Column 1"</span>)
plt.<span class="hljs-built_in">ylabel</span>(<span class="hljs-string">"Column 2"</span>)
plt.<span class="hljs-built_in">title</span>(<span class="hljs-string">"Scatter Plot"</span>)
plt.<span class="hljs-built_in">show</span>()
</code></pre>
<p>This code now generates a sample DataFrame with two columns, <code>column1</code> and <code>column2</code>, containing random values. The rest of the code remains the same, demonstrating how to display the DataFrame&#39;s contents and create a scatter plot using the generated data.</p>
<p>To save your notebook, click the save icon in the toolbar or use the <code>Ctrl + S</code> shortcut. Don&#39;t forget to rename your Notebook. You can right-click on the Notebook tab or the Notebook in the file browser.</p>
<h3 id="restarting-the-kernel">Restarting the Kernel</h3>
<p><code>JupyterLab</code> uses a <code>kernel</code> to run your code. The <code>kernel</code> is a separate process responsible for executing code and maintaining the state of your computations. Sometimes, you may need to reset your environment if it becomes cluttered with variables or you encounter unexpected behavior.</p>
<p>Restarting the <code>kernel</code> clears all variables, functions, and imported modules from memory, allowing you to start fresh without shutting down <code>JupyterLab</code> entirely.</p>
<p>To restart the <code>kernel</code>:</p>
<ol>
<li>Open the <code>Kernel</code> menu in the top toolbar.</li>
<li>Select <code>Restart Kernel</code> to reset the environment while preserving cell outputs, or <code>Restart Kernel and Clear All Outputs</code> to also remove all previously generated outputs from the notebook.</li>
</ol>
<p>After restarting, re-run any cells containing variable definitions, imports, or computations to restore the environment. This ensures that the notebook state accurately reflects the code you have most recently executed.</p>
<p>This is just a brief overview of Jupyter to get you up and running for this module. For an in-depth guide, refer to the <a href="https://jupyterlab.readthedocs.io/en/latest/getting_started/overview.html">JupyerLab Documentation</a>.</p>
<hr>
<h2 id="python-libraries-for-ai">Python Libraries for AI</h2>
<hr>
<p>Python is a versatile programming language widely used in Artificial Intelligence (AI) due to its rich library ecosystem that provides efficient and user-friendly tools for developing AI applications. This section focuses on two prominent Python libraries for AI development: <code>Scikit-learn</code> and <code>PyTorch</code>.</p>
<p>Just a quick note. This section provides a high-level overview of key Python libraries for AI, aiming to familiarize you with their purpose, structure, and common use cases. It offers a foundation for identifying relevant APIs and understanding the general landscape of these libraries. The official documentation will be your best resource to learning every small detail about the libraries. You do not need to copy and run these code snippets.</p>
<h3 id="scikit-learn">Scikit-learn</h3>
<p><code>Scikit-learn</code> is a comprehensive library built on <code>NumPy</code>, <code>SciPy</code>, and <code>Matplotlib</code>. It offers a wide range of algorithms and tools for machine learning tasks and provides a consistent and intuitive API, making implementing various machine learning models easy.</p>
<ul>
<li><code>Supervised Learning:</code> <code>Scikit-learn</code> provides a vast collection of supervised learning algorithms, including:<ul>
<li><code>Linear Regression</code></li>
<li><code>Logistic Regression</code></li>
<li><code>Support Vector Machines (SVMs)</code></li>
<li><code>Decision Trees</code></li>
<li><code>Naive Bayes</code></li>
<li><code>Ensemble Methods</code> (e.g., Random Forests, Gradient Boosting)</li>
</ul>
</li>
<li><code>Unsupervised Learning:</code> It also offers various unsupervised learning algorithms, such as:<ul>
<li><code>Clustering</code> (K-Means, DBSCAN)</li>
<li><code>Dimensionality Reduction</code> (PCA, t-SNE)</li>
</ul>
</li>
<li><code>Model Selection and Evaluation:</code> <code>Scikit-learn</code> includes tools for model selection, hyperparameter tuning, and performance evaluation, enabling developers to optimize their models effectively.</li>
<li><code>Data Preprocessing:</code> It provides functionalities for data preprocessing, including:<ul>
<li>Feature scaling and normalization</li>
<li>Handling missing values</li>
<li>Encoding categorical variables</li>
</ul>
</li>
</ul>
<h4 id="data-preprocessing">Data Preprocessing</h4>
<p><code>Scikit-learn</code> offers a rich set of tools for preprocessing data, a crucial step in preparing data for machine learning algorithms. These tools help transform raw data into a suitable format that improves the accuracy and efficiency of models.</p>
<p>Feature scaling is essential to ensure that all features have a similar scale, preventing features with larger values from dominating the learning process. <code>Scikit-learn</code> provides various scaling techniques:</p>
<ul>
<li><code>StandardScaler</code> : Standardizes features by removing the mean and scaling to unit variance.</li>
<li><code>MinMaxScaler</code> : Scales features to a given range, typically between 0 and 1.</li>
<li><code>RobustScaler</code> : Scales features using statistics that are robust to outliers.</li>
</ul>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.preprocessing <span class="hljs-built_in">import</span> StandardScaler

<span class="hljs-attr">scaler</span> = StandardScaler()
<span class="hljs-attr">X_scaled</span> = scaler.fit_transform(X)
</code></pre>
<p>Categorical features, representing data in categories or groups, need to be converted into numerical representations for machine learning algorithms to process them. <code>Scikit-learn</code> offers encoding techniques:</p>
<ul>
<li><code>OneHotEncoder</code> : Creates binary (0 or 1) columns for each category.</li>
<li><code>LabelEncoder</code> : Assigns a unique integer to each category.</li>
</ul>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.preprocessing <span class="hljs-built_in">import</span> OneHotEncoder

<span class="hljs-attr">encoder</span> = OneHotEncoder()
<span class="hljs-attr">X_encoded</span> = encoder.fit_transform(X)
</code></pre>
<p>Real-world datasets often contain missing values. <code>Scikit-learn</code> provides methods to handle these missing values:</p>
<ul>
<li><code>SimpleImputer</code> : Replaces missing values with a specified strategy (e.g., mean, median, most frequent).</li>
<li><code>KNNImputer</code> : Imputes missing values using the k-Nearest Neighbors algorithm.</li>
</ul>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.impute <span class="hljs-built_in">import</span> SimpleImputer

<span class="hljs-attr">imputer</span> = SimpleImputer(<span class="hljs-attr">strategy='mean')</span>
<span class="hljs-attr">X_imputed</span> = imputer.fit_transform(X)
</code></pre>
<h4 id="model-selection-and-evaluation">Model Selection and Evaluation</h4>
<p><code>Scikit-learn</code> offers tools for selecting the best model and evaluating its performance.</p>
<p>Splitting data into training and testing sets is crucial to evaluating the model&#39;s generalization ability to unseen data.</p>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.model_selection <span class="hljs-built_in">import</span> train_test_split

X_train, X_test, y_train, <span class="hljs-attr">y_test</span> = train_test_split(X, y, <span class="hljs-attr">test_size=0.2)</span>
</code></pre>
<p>Cross-validation provides a more robust evaluation by splitting the data into multiple folds and training/testing on different combinations.</p>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.model_selection <span class="hljs-built_in">import</span> cross_val_score

<span class="hljs-attr">scores</span> = cross_val_score(model, X, y, <span class="hljs-attr">cv=5)</span>
</code></pre>
<p><code>Scikit-learn</code> provides various metrics to evaluate model performance:</p>
<ul>
<li><code>accuracy_score</code> : For classification tasks.</li>
<li><code>mean_squared_error</code> : For regression tasks.</li>
<li><code>precision_score</code>, <code>recall_score</code>, <code>f1_score</code> : For classification tasks with imbalanced classes.</li>
</ul>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score

accuracy = accuracy_score(y_test, y_pred)
</code></pre>
<h4 id="model-training-and-prediction">Model Training and Prediction</h4>
<p><code>Scikit-learn</code> follows a consistent API for training and predicting with different models.</p>
<p>Create an instance of the desired model with appropriate hyperparameters.</p>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.linear_model <span class="hljs-built_in">import</span> LogisticRegression

<span class="hljs-attr">model</span> = LogisticRegression(<span class="hljs-attr">C=1.0)</span>
</code></pre>
<p>Train the model using the <code>fit()</code> method with the training data.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-selector-tag">model</span><span class="hljs-selector-class">.fit</span>(<span class="hljs-selector-tag">X_train</span>, <span class="hljs-selector-tag">y_train</span>)
</code></pre>
<p>Make predictions on new data using the <code>predict()</code> method.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-attr">y_pred</span> = model.predict(X_test)
</code></pre>
<h3 id="pytorch">PyTorch</h3>
<p><code>PyTorch</code> is an open-source machine learning library developed by Facebook&#39;s AI Research lab. It provides a flexible and powerful framework for building and deploying various types of machine learning models, including deep learning models.</p>
<h4 id="key-features">Key Features</h4>
<ul>
<li><code>Deep Learning:</code> <code>PyTorch</code> excels in deep learning, enabling the development of complex neural networks with multiple layers and architectures.</li>
<li><code>Dynamic Computational Graphs:</code> Unlike static computational graphs used in libraries like TensorFlow, <code>PyTorch</code> uses dynamic computational graphs, which allow for more flexible and intuitive model building and debugging.</li>
<li><code>GPU Support:</code> <code>PyTorch</code> supports GPU acceleration, significantly speeding up the training process for computationally intensive models.</li>
<li><code>TorchVision Integration:</code> <code>TorchVision</code> is a library integrated with <code>PyTorch</code> that provides a user-friendly interface for image datasets, pre-trained models, and common image transformations.</li>
<li><code>Automatic Differentiation:</code> <code>PyTorch</code> uses <code>autograd</code> to automatically compute gradients, simplifying the process of backpropagation.</li>
<li><code>Community and Ecosystem:</code> <code>PyTorch</code> has a large and active community, leading to a rich ecosystem of tools, libraries, and resources.</li>
</ul>
<h4 id="dynamic-computational-graphs-and-tensors">Dynamic Computational Graphs and Tensors</h4>
<p>At the heart of <code>PyTorch</code> lies the concept of dynamic computational graphs. A dynamic computational graph is created on the fly during the forward pass, allowing for more flexible and dynamic model building. This makes it easier to implement complex and non-linear models.</p>
<p><code>Tensors</code> are multi-dimensional arrays that hold the data being processed. They can be constants, variables, or placeholders. <code>PyTorch</code> tensors are similar to NumPy arrays but can run on GPUs for faster computation.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch

<span class="hljs-comment"># Creating a tensor</span>
x = torch.tensor([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>])

<span class="hljs-comment"># Tensors can be moved to GPU if available</span>
<span class="hljs-keyword">if</span> torch.cuda.is_available():
    x = x.<span class="hljs-keyword">to</span>(<span class="hljs-string">'cuda'</span>)
</code></pre>
<h4 id="building-models-with-pytorch">Building Models with PyTorch</h4>
<p><code>PyTorch</code> provides a flexible and intuitive interface for building and training deep learning models. The <code>torch.nn</code> module contains various layers and modules for constructing neural networks.</p>
<p>The <code>Sequential</code> API allows building models layer by layer, adding each layer sequentially.</p>
<p>Code: python</p>
<pre><code class="lang-python">import torch.<span class="hljs-keyword">nn</span> <span class="hljs-keyword">as</span> <span class="hljs-keyword">nn</span>

model = <span class="hljs-keyword">nn</span>.Sequential(
    <span class="hljs-keyword">nn</span>.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">128</span>),
    <span class="hljs-keyword">nn</span>.ReLU(),
    <span class="hljs-keyword">nn</span>.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>),
    <span class="hljs-keyword">nn</span>.Softmax(dim=<span class="hljs-number">1</span>)
)
</code></pre>
<p>The <code>Module</code> class provides more flexibility for building complex models with non-linear topologies, shared layers, and multiple inputs/outputs.</p>
<p>Code: python</p>
<pre><code class="lang-python">import torch.nn as nn

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomModel</span>(<span class="hljs-title">nn</span>.<span class="hljs-title">Module</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>)</span></span>:
        <span class="hljs-keyword">super</span>(CustomModel, <span class="hljs-keyword">self</span>).__init_<span class="hljs-number">_</span>()
        <span class="hljs-keyword">self</span>.layer1 = nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">128</span>)
        <span class="hljs-keyword">self</span>.relu = nn.ReLU()
        <span class="hljs-keyword">self</span>.layer2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)
        <span class="hljs-keyword">self</span>.softmax = nn.Softmax(dim=<span class="hljs-number">1</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, x)</span></span>:
        x = <span class="hljs-keyword">self</span>.layer1(x)
        x = <span class="hljs-keyword">self</span>.relu(x)
        x = <span class="hljs-keyword">self</span>.layer2(x)
        x = <span class="hljs-keyword">self</span>.softmax(x)
        <span class="hljs-keyword">return</span> x

model = CustomModel()
</code></pre>
<h4 id="training-and-evaluation">Training and Evaluation</h4>
<p><code>PyTorch</code> provides tools for training and evaluating models.</p>
<p><code>Optimizers</code> are algorithms that adjust the model&#39;s parameters during training to minimize the loss function. <code>PyTorch</code> offers various optimizers:</p>
<ul>
<li><code>Adam</code></li>
<li><code>SGD</code> (Stochastic Gradient Descent)</li>
<li><code>RMSprop</code></li>
</ul>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim

<span class="hljs-title">optimizer</span> = optim.<span class="hljs-type">Adam</span>(model.parameters(), lr=<span class="hljs-number">0.001</span>)
</code></pre>
<p><code>Loss Functions</code> measure the difference between the model&#39;s predictions and the actual target values. <code>PyTorch</code> provides a variety of loss functions:</p>
<ul>
<li><code>CrossEntropyLoss</code> : For multi-class classification.</li>
<li><code>BCEWithLogitsLoss</code> : For binary classification.</li>
<li><code>MSELoss</code> : For regression.</li>
</ul>
<p>Code: python</p>
<pre><code class="lang-python">import torch.<span class="hljs-keyword">nn</span> <span class="hljs-keyword">as</span> <span class="hljs-keyword">nn</span>

loss_fn = <span class="hljs-keyword">nn</span>.CrossEntropyLoss()
</code></pre>
<p><code>Metrics</code> evaluate the model&#39;s performance during training and testing.</p>
<ul>
<li><code>Accuracy</code></li>
<li><code>Precision</code></li>
<li><code>Recall</code></li>
</ul>
<p>Code: python</p>
<pre><code class="lang-python">def accuracy(output, <span class="hljs-keyword">target</span>):
    _, predicted = torch.max(output, 1)
    correct = (predicted == <span class="hljs-keyword">target</span>).sum().item()
    <span class="hljs-keyword">return</span> correct / len(<span class="hljs-keyword">target</span>)
</code></pre>
<p>The training loop updates the model&#39;s parameters based on the training data.</p>
<p>Code: python</p>
<pre><code class="lang-python">import torch

epochs = <span class="hljs-number">10</span>
num_batches = <span class="hljs-number">100</span>

<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):
    <span class="hljs-keyword">for</span> <span class="hljs-built_in">batch</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_batches):
        # Get <span class="hljs-built_in">batch</span> of data
        x_batch, y_batch = get_batch(<span class="hljs-built_in">batch</span>)

        # Forward pass
        y_pred = model(x_batch)

        # Calculate loss
        loss = loss_fn(y_pred, y_batch)

        # Backward pass <span class="hljs-keyword">and</span> optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.<span class="hljs-keyword">step</span>()

        # Optional: <span class="hljs-built_in">print</span> loss <span class="hljs-keyword">or</span> other metrics
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">batch</span> <span class="hljs-symbol">%</span> <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:
            <span class="hljs-built_in">print</span>(f'Epoch [{epoch+<span class="hljs-number">1</span>}/{epochs}], Batch [{<span class="hljs-built_in">batch</span>+<span class="hljs-number">1</span>}/{num_batches}], Loss: {loss.item():.4f}')
</code></pre>
<h4 id="data-loading-and-preprocessing">Data Loading and Preprocessing</h4>
<p><code>PyTorch</code> provides the <code>torch.utils.data.Dataset</code> and <code>DataLoader</code> classes for handling data loading and preprocessing.</p>
<p>Code: python</p>
<pre><code class="lang-python">from torch.utils.data import Dataset, DataLoader

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomDataset</span>(<span class="hljs-title">Dataset</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, data, labels)</span></span>:
        <span class="hljs-keyword">self</span>.data = data
        <span class="hljs-keyword">self</span>.labels = labels

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>)</span></span>:
        <span class="hljs-keyword">return</span> len(<span class="hljs-keyword">self</span>.data)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, idx)</span></span>:
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.data[idx], <span class="hljs-keyword">self</span>.labels[idx]

<span class="hljs-comment"># Example usage</span>
dataset = CustomDataset(data, labels)
dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">32</span>, shuffle=True)
</code></pre>
<h4 id="model-saving-and-loading">Model Saving and Loading</h4>
<p><code>PyTorch</code> allows models to be saved and loaded for inference or further training.</p>
<p>Code: python</p>
<pre><code class="lang-python"># Save <span class="hljs-keyword">model</span>
torch.save(<span class="hljs-keyword">model</span>.state_dict(), <span class="hljs-string">'model.pth'</span>)

# Load <span class="hljs-keyword">model</span>
<span class="hljs-keyword">model</span> = CustomModel()
<span class="hljs-keyword">model</span>.load_state_dict(torch.load(<span class="hljs-string">'model.pth'</span>))
<span class="hljs-keyword">model</span>.eval()  # <span class="hljs-keyword">Set</span> the <span class="hljs-comment">model to evaluation mode</span>
</code></pre>
<hr>
<h2 id="datasets">Datasets</h2>
<hr>
<p>In AI, the quality and characteristics of the data used to train models significantly impact their performance and accuracy. <code>Datasets</code>, which are collections of data points used for analysis and model training, come in various forms and formats, each with its own properties and considerations. <code>Data preprocessing</code> is a crucial step in the machine-learning pipeline that involves transforming raw data into a suitable format for algorithms to process effectively.</p>
<h3 id="understanding-datasets">Understanding Datasets</h3>
<p><code>Datasets</code> are structured collections of data used for analysis and model training. They come in various forms, including:</p>
<ul>
<li><code>Tabular Data</code>: Data organized into tables with rows and columns, common in spreadsheets or databases.</li>
<li><code>Image Data</code>: Sets of images represented numerically as pixel arrays.</li>
<li><code>Text Data</code>: Unstructured data composed of sentences, paragraphs, or full documents.</li>
<li><code>Time Series Data</code>: Sequential data points collected over time, emphasizing temporal patterns.</li>
</ul>
<p>The quality of a dataset is fundamental to the success of any data analysis or machine learning project. Here’s why:</p>
<ul>
<li><code>Model Accuracy</code>: High-quality datasets produce more accurate models. Poor-quality data—such as noisy, incomplete, or biased datasets—leads to reduced model performance.</li>
<li><code>Generalization</code>: Carefully curated datasets enable models to generalize effectively to unseen data. This minimizes overfitting and ensures consistent performance in real-world applications.</li>
<li><code>Efficiency</code>: Clean, well-prepared data reduces both training time and computational demands, streamlining the entire process.</li>
<li><code>Reliability</code>: Reliable datasets lead to trustworthy insights and decisions. In critical domains like healthcare or finance, data quality directly affects the dependability of results.</li>
</ul>
<h4 id="what-makes-a-dataset-good-">What Makes a Dataset &#39;Good&#39;</h4>
<p>Several key attributes characterize a good dataset:</p>
<table>
<thead>
<tr>
<th>Attribute</th>
<th>Description</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Relevance</code></td>
<td>The data should be relevant to the problem at hand. Irrelevant data can introduce noise and reduce model performance.</td>
<td>Text data from social media posts is more relevant than stock market prices for a sentiment analysis task.</td>
</tr>
<tr>
<td><code>Completeness</code></td>
<td>The dataset should have minimal missing values. Missing data can lead to biased models and incorrect predictions.</td>
<td>Techniques like imputation can handle missing values, but it&#39;s best to start with a complete dataset if possible.</td>
</tr>
<tr>
<td><code>Consistency</code></td>
<td>Data should be consistent in format and structure. Inconsistencies can cause errors during preprocessing and model training.</td>
<td>Ensure that date formats are uniform across the dataset (e.g.,<code>YYYY-MM-DD</code>).</td>
</tr>
<tr>
<td><code>Quality</code></td>
<td>The data should be accurate and free from errors. Errors can arise from data collection, entry, or transmission issues.</td>
<td>Data validation and verification processes can help ensure data quality.</td>
</tr>
<tr>
<td><code>Representativeness</code></td>
<td>The dataset should be representative of the population it aims to model. A biased or unrepresentative dataset can lead to biased models.</td>
<td>A facial recognition system&#39;s dataset should include a diverse range of faces from different ethnicities, ages, and genders.</td>
</tr>
<tr>
<td><code>Balance</code></td>
<td>The dataset should be balanced, especially for classification tasks. Imbalanced datasets can lead to biased models that perform poorly on minority classes.</td>
<td>Techniques like oversampling, undersampling, or generating synthetic data can help balance the dataset.</td>
</tr>
<tr>
<td><code>Size</code></td>
<td>The dataset should be large enough to capture the complexity of the problem. Small datasets may not provide enough information for the model to learn effectively.</td>
<td>However, large datasets can also be computationally expensive and require more powerful hardware.</td>
</tr>
</tbody>
</table>
<h3 id="the-dataset">The Dataset</h3>
<p>The provided dataset, <a href="https://academy.hackthebox.com/storage/modules/292/demo_dataset.zip">demo_dataset.csv</a> is a <code>CSV</code> file containing network log entries. Each record describes a network event and includes details such as the source IP address, destination port, protocol used, the volume of data transferred, and an associated threat level. Analyzing these entries allows one to simulate various network scenarios that are useful for developing and evaluating intrusion detection systems.</p>
<h4 id="dataset-structure">Dataset Structure</h4>
<p>The dataset consists of multiple columns, each serving a specific purpose:</p>
<ul>
<li><code>log_id</code>: Unique identifier for each log entry.</li>
<li><code>source_ip</code>: Source IP address for the network event.</li>
<li><code>destination_port</code>: Destination port number used by the event.</li>
<li><code>protocol</code>: Network protocol employed (e.g., <code>TCP</code>, <code>TLS</code>, <code>SSH</code>).</li>
<li><code>bytes_transferred</code>: Total bytes transferred during the event.</li>
<li><code>threat_level</code>: Indicator of the event&#39;s severity. <code>0</code> denotes normal traffic, <code>1</code> indicates low-threat activity, and <code>2</code> signifies a high-threat event.</li>
</ul>
<h4 id="challenges-and-considerations">Challenges and Considerations</h4>
<p>Before processing, it is essential to note potential difficulties:</p>
<ul>
<li>The dataset contains a mix of numerical and categorical data.</li>
<li>Missing values and invalid entries appear in some columns, requiring data cleaning.</li>
<li>Certain numeric columns may contain non-numeric strings, which must be converted or removed.</li>
<li>The <code>threat_level</code> column includes unknown values (e.g., <code>?</code>, <code>-1</code>) that must be standardized or addressed during preprocessing.</li>
</ul>
<p>Acknowledging these challenges early allows the data to be properly cleaned and transformed, facilitating accurate and reliable analysis.</p>
<h3 id="loading-the-dataset">Loading the Dataset</h3>
<p>We first load it into a <code>pandas DataFrame</code> to begin working with the dataset. A <code>pandas DataFrame</code> is a flexible, two-dimensional labeled data structure that supports a variety of operations for data exploration and preprocessing. Key advantages include labeled axes, heterogeneous data handling, and integration with other Python libraries.</p>
<p>Utilizing a DataFrame simplifies subsequent tasks like inspection, cleaning, encoding, and data transformation.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

<span class="hljs-comment"># Load the dataset</span>
data = pd.read_csv(<span class="hljs-string">"./demo_dataset.csv"</span>)
</code></pre>
<p>In this code, <code>pd.read_csv(&quot;./demo_dataset.csv&quot;)</code> loads the downloaded CSV file into a DataFrame named <code>data</code>. From here, inspecting, manipulating, and preparing the dataset for further steps in the analysis pipeline becomes straightforward.</p>
<h3 id="exploring-the-dataset">Exploring the Dataset</h3>
<p>After loading the dataset, we employ various operations to understand its structure, identify anomalies, and determine the nature of cleaning or transformations needed.</p>
<h4 id="viewing-sample-entries">Viewing Sample Entries</h4>
<p>We examine the first few rows to get a quick overview, which can help detect obvious issues like unexpected column names, incorrect data types, or irregular patterns.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Display the first few rows of the dataset</span>
<span class="hljs-built_in">print</span>(data.head())
</code></pre>
<p>This command outputs the initial rows of the DataFrame, offering an immediate glimpse into the dataset&#39;s overall organization.</p>
<h4 id="inspecting-data-structure-and-types">Inspecting Data Structure and Types</h4>
<p>Understanding the data types and completeness of each column is essential. We can quickly review the dataset&#39;s information, including which columns have null values and the total number of entries per column.</p>
<p>Code: python</p>
<pre><code class="lang-python"># <span class="hljs-meta">Get</span> a summary of column <span class="hljs-meta">data</span> types <span class="hljs-keyword">and </span>non-null counts
<span class="hljs-symbol">print</span>(<span class="hljs-meta">data</span>.info())
</code></pre>
<p>The <code>info()</code> method reveals the dataset&#39;s shape, column names, data types, and how many entries are present for each column, enabling early detection of columns with missing or unexpected data.</p>
<h4 id="checking-for-missing-values">Checking for Missing Values</h4>
<p>Missing values or anomalies must be handled to maintain the dataset&#39;s integrity. The next step is to identify how many missing values each column contains.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-meta"># Identify columns with missing values</span>
<span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>.isnull().sum())</span>
</code></pre>
<p>This command returns the count of null values for each column, helping to prioritize which features need attention. Addressing these missing values may involve imputation, removal, or other cleaning strategies to ensure the dataset remains reliable and valid for further analysis.</p>
<hr>
<h2 id="data-preprocessing">Data Preprocessing</h2>
<hr>
<p><code>Data preprocessing</code> transforms raw data into a suitable format for machine learning algorithms. Key techniques include:</p>
<ul>
<li><code>Data Cleaning</code>: Handling missing values, removing duplicates, and smoothing noisy data.</li>
<li><code>Data Transformation</code>: Normalizing, encoding, scaling, and reducing data.</li>
<li><code>Data Integration</code>: Merging and aggregating data from multiple sources.</li>
<li><code>Data Formatting</code>: Converting data types and reshaping data structures.</li>
</ul>
<p>Effective preprocessing addresses inconsistencies, missing values, outliers, noise, and feature scaling, improving the accuracy, efficiency, and robustness of machine learning models.</p>
<h3 id="identifying-invalid-values">Identifying Invalid Values</h3>
<p>In addition to missing values, we need to check for invalid values in specific columns. Here are some common checks for the given dataset.</p>
<h4 id="checking-for-invalid-ip-addresses">Checking for Invalid IP Addresses</h4>
<p>To identify invalid <code>source_ip</code> values, you can use a regular expression to validate the IP addresses:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> re

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">is_valid_ip</span><span class="hljs-params">(ip)</span>:</span>
    pattern = re.compile(<span class="hljs-string">r'^((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$'</span>)
    <span class="hljs-keyword">return</span> bool(pattern.match(ip))

<span class="hljs-comment"># Check for invalid IP addresses</span>
invalid_ips = data[~data[<span class="hljs-string">'source_ip'</span>].astype(str).apply(is_valid_ip)]
print(invalid_ips)
</code></pre>
<h4 id="checking-for-invalid-port-numbers">Checking for Invalid Port Numbers</h4>
<p>To identify invalid <code>destination_port</code> values, you can check if the port numbers are within the valid range (0-65535):</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">is_valid_port</span><span class="hljs-params">(port)</span>:</span>
    <span class="hljs-keyword">try</span>:
        port = int(port)
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span> &lt;= port &lt;= <span class="hljs-number">65535</span>
    <span class="hljs-keyword">except</span> ValueError:
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">False</span>

<span class="hljs-comment"># Check for invalid port numbers</span>
invalid_ports = data[~data[<span class="hljs-string">'destination_port'</span>].apply(is_valid_port)]
print(invalid_ports)
</code></pre>
<h4 id="checking-for-invalid-protocol-values">Checking for Invalid Protocol Values</h4>
<p>To identify invalid <code>protocol</code> values, you can check against a list of known protocols:</p>
<p>Code: python</p>
<pre><code class="lang-python">valid_protocols = [<span class="hljs-string">'TCP'</span>, <span class="hljs-string">'TLS'</span>, <span class="hljs-string">'SSH'</span>, <span class="hljs-string">'POP3'</span>, <span class="hljs-string">'DNS'</span>, <span class="hljs-string">'HTTPS'</span>, <span class="hljs-string">'SMTP'</span>, <span class="hljs-string">'FTP'</span>, <span class="hljs-string">'UDP'</span>, <span class="hljs-string">'HTTP'</span>]

# Check <span class="hljs-keyword">for</span> invalid protocol values
invalid_protocols = <span class="hljs-keyword">data</span>[~<span class="hljs-keyword">data</span>[<span class="hljs-string">'protocol'</span>].isin(valid_protocols)]
print(invalid_protocols)
</code></pre>
<h4 id="checking-for-invalid-bytes-transferred">Checking for Invalid Bytes Transferred</h4>
<p>To identify invalid <code>bytes_transferred</code> values, you can check if the values are numeric and non-negative:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">is_valid_bytes</span><span class="hljs-params">(bytes)</span>:</span>
    <span class="hljs-keyword">try</span>:
        bytes = int(bytes)
        <span class="hljs-keyword">return</span> bytes &gt;= <span class="hljs-number">0</span>
    <span class="hljs-keyword">except</span> ValueError:
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">False</span>

<span class="hljs-comment"># Check for invalid bytes transferred</span>
invalid_bytes = data[~data[<span class="hljs-string">'bytes_transferred'</span>].apply(is_valid_bytes)]
print(invalid_bytes)
</code></pre>
<h4 id="checking-for-invalid-threat-levels">Checking for Invalid Threat Levels</h4>
<p>To identify invalid <code>threat_level</code> values, you can check if the values are within a valid range (e.g., 0-2):</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">is_valid_threat_level</span><span class="hljs-params">(threat_level)</span>:</span>
    <span class="hljs-keyword">try</span>:
        threat_level = int(threat_level)
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span> &lt;= threat_level &lt;= <span class="hljs-number">2</span>
    <span class="hljs-keyword">except</span> ValueError:
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">False</span>

<span class="hljs-comment"># Check for invalid threat levels</span>
invalid_threat_levels = data[~data[<span class="hljs-string">'threat_level'</span>].apply(is_valid_threat_level)]
print(invalid_threat_levels)
</code></pre>
<h3 id="handling-invalid-entries">Handling Invalid Entries</h3>
<p>There are a few different ways we can approach this bad data.</p>
<h4 id="dropping-invalid-entries">Dropping Invalid Entries</h4>
<p>The most straightforward approach is to discard the invalid entries entirely. This ensures that the remaining dataset is clean and free of potentially misleading information.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-meta"># the ignore errors covers the fact that there might be some overlap between indexes that match other invalid criteria</span>
<span class="hljs-class"><span class="hljs-keyword">data</span> = <span class="hljs-keyword">data</span>.drop(<span class="hljs-title">invalid_ips</span>.<span class="hljs-title">index</span>, <span class="hljs-title">errors</span>='<span class="hljs-title">ignore'</span>) </span>
<span class="hljs-class"><span class="hljs-keyword">data</span> = <span class="hljs-keyword">data</span>.drop(<span class="hljs-title">invalid_ports</span>.<span class="hljs-title">index</span>, <span class="hljs-title">errors</span>='<span class="hljs-title">ignore'</span>)</span>
<span class="hljs-class"><span class="hljs-keyword">data</span> = <span class="hljs-keyword">data</span>.drop(<span class="hljs-title">invalid_protocols</span>.<span class="hljs-title">index</span>, <span class="hljs-title">errors</span>='<span class="hljs-title">ignore'</span>)</span>
<span class="hljs-class"><span class="hljs-keyword">data</span> = <span class="hljs-keyword">data</span>.drop(<span class="hljs-title">invalid_bytes</span>.<span class="hljs-title">index</span>, <span class="hljs-title">errors</span>='<span class="hljs-title">ignore'</span>)</span>
<span class="hljs-class"><span class="hljs-keyword">data</span> = <span class="hljs-keyword">data</span>.drop(<span class="hljs-title">invalid_threat_levels</span>.<span class="hljs-title">index</span>, <span class="hljs-title">errors</span>='<span class="hljs-title">ignore'</span>)</span>

<span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>.describe(<span class="hljs-title">include</span>='<span class="hljs-title">all'</span>))</span>
</code></pre>
<p>This method is generally preferred when data accuracy is paramount, and the loss of some data points does not significantly compromise the overall analysis. However, it may not always be feasible, especially if the dataset is small or the invalid entries constitute a substantial portion of the data.</p>
<p>After dropping the bad data from our dataset, we are only left with 77 clean entries.</p>
<p>It is sometimes possible to clean or transform invalid entries into valid and usable data instead of discarding them. This approach aims to retain as much information as possible from the dataset.</p>
<h4 id="imputing-missing-values">Imputing Missing Values</h4>
<p><code>Imputing</code> is the process of replacing missing or invalid values in a dataset with estimated values. This is crucial for maintaining the integrity and usability of the data, especially in machine learning and data analysis tasks where missing values can lead to biased or inaccurate results.</p>
<p>First, convert all invalid or corrupted entries, such as <code>MISSING_IP</code>, <code>INVALID_IP</code>, <code>STRING_PORT</code>, <code>UNUSED_PORT</code>, <code>NON_NUMERIC</code>, or <code>?</code>, into <code>NaN</code>. This approach standardizes the representation of missing values, enabling uniform downstream imputation steps.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> re
<span class="hljs-keyword">from</span> ipaddress <span class="hljs-keyword">import</span> ip_address

df = pd.read_csv(<span class="hljs-string">'demo_dataset.csv'</span>)

invalid_ips = [<span class="hljs-string">'INVALID_IP'</span>, <span class="hljs-string">'MISSING_IP'</span>]
invalid_ports = [<span class="hljs-string">'STRING_PORT'</span>, <span class="hljs-string">'UNUSED_PORT'</span>]
invalid_bytes = [<span class="hljs-string">'NON_NUMERIC'</span>, <span class="hljs-string">'NEGATIVE'</span>]
invalid_threat = [<span class="hljs-string">'?'</span>]

df.replace(invalid_ips + invalid_ports + invalid_bytes + invalid_threat, np.nan, inplace=<span class="hljs-keyword">True</span>)

df[<span class="hljs-string">'destination_port'</span>] = pd.to_numeric(df[<span class="hljs-string">'destination_port'</span>], errors=<span class="hljs-string">'coerce'</span>)
df[<span class="hljs-string">'bytes_transferred'</span>] = pd.to_numeric(df[<span class="hljs-string">'bytes_transferred'</span>], errors=<span class="hljs-string">'coerce'</span>)
df[<span class="hljs-string">'threat_level'</span>] = pd.to_numeric(df[<span class="hljs-string">'threat_level'</span>], errors=<span class="hljs-string">'coerce'</span>)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">is_valid_ip</span><span class="hljs-params">(ip)</span>:</span>
    pattern = re.compile(<span class="hljs-string">r'^((25[0-5]|2[0-4][0-9]|[01]?\d?\d)\.){3}(25[0-5]|2[0-4]\d|[01]?\d?\d)$'</span>)
    <span class="hljs-keyword">if</span> pd.isna(ip) <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> pattern.match(str(ip)):
        <span class="hljs-keyword">return</span> np.nan
    <span class="hljs-keyword">return</span> ip

df[<span class="hljs-string">'source_ip'</span>] = df[<span class="hljs-string">'source_ip'</span>].apply(is_valid_ip)
</code></pre>
<p>After this step, <code>NaN</code> represents all missing or invalid data points.</p>
<p>For basic numeric columns like <code>bytes_transferred</code>, use simple methods such as the median or mean. For categorical columns like <code>protocol</code>, use the most frequent value.</p>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.impute import <span class="hljs-symbol">SimpleImputer</span>

numeric_cols = [<span class="hljs-string">'destination_port'</span>, <span class="hljs-string">'bytes_transferred'</span>, <span class="hljs-string">'threat_level'</span>]
categorical_cols = [<span class="hljs-string">'protocol'</span>]

num_imputer = <span class="hljs-symbol">SimpleImputer</span>(strategy=<span class="hljs-string">'median'</span>)
df[numeric_cols] = num_imputer.fit_transform(df[numeric_cols])

cat_imputer = <span class="hljs-symbol">SimpleImputer</span>(strategy=<span class="hljs-string">'most_frequent'</span>)
df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])
</code></pre>
<p>These imputations ensure that all columns have valid, non-missing values, though they do not consider complex relationships among features.</p>
<p>For more sophisticated scenarios, employ advanced techniques like <code>KNNImputer</code> or <code>IterativeImputer</code>. These methods consider relationships among features to produce contextually meaningful imputations.</p>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.impute <span class="hljs-built_in">import</span> KNNImputer

<span class="hljs-attr">knn_imputer</span> = KNNImputer(<span class="hljs-attr">n_neighbors=5)</span>
df[numeric_cols] = knn_imputer.fit_transform(df[numeric_cols])
</code></pre>
<p>After cleaning and imputations, apply domain knowledge. For <code>source_ip</code> values that remain missing, assign a default such as <code>0.0.0.0</code>. Validate <code>protocol</code> values against known valid protocols. For ports, ensure values fall within the valid range <code>0-65535</code>, and for protocols that imply certain ports, consider mode-based assignments or domain-specific mappings.</p>
<p>Code: python</p>
<pre><code class="lang-python">valid_protocols = [<span class="hljs-string">'TCP'</span>, <span class="hljs-string">'TLS'</span>, <span class="hljs-string">'SSH'</span>, <span class="hljs-string">'POP3'</span>, <span class="hljs-string">'DNS'</span>, <span class="hljs-string">'HTTPS'</span>, <span class="hljs-string">'SMTP'</span>, <span class="hljs-string">'FTP'</span>, <span class="hljs-string">'UDP'</span>, <span class="hljs-string">'HTTP'</span>]
df.loc[~df[<span class="hljs-string">'protocol'</span>].isin(valid_protocols), <span class="hljs-string">'protocol'</span>] = df[<span class="hljs-string">'protocol'</span>].mode()[<span class="hljs-number">0</span>]

df[<span class="hljs-string">'source_ip'</span>] = df[<span class="hljs-string">'source_ip'</span>].fillna(<span class="hljs-string">'0.0.0.0'</span>)
df[<span class="hljs-string">'destination_port'</span>] = df[<span class="hljs-string">'destination_port'</span>].clip(lower=<span class="hljs-number">0</span>, upper=<span class="hljs-number">65535</span>)
</code></pre>
<p>Perform final verification steps to confirm that distributions are reasonable and categorical sets remain valid. Adjust imputation strategies and transformations or remove problematic records if anomalies persist.</p>
<p>Code: python</p>
<pre><code class="lang-python">print(<span class="hljs-name">df</span>.describe(<span class="hljs-name">include=</span>'all'))
</code></pre>
<hr>
<h2 id="data-transformation">Data Transformation</h2>
<hr>
<p><code>Data transformations</code> improve the representation and distribution of features, making them more suitable for machine learning models. These transformations ensure that models can efficiently capture underlying patterns by converting categorical variables into machine-readable formats and addressing skewed numerical distributions. They also enhance trained models&#39; stability, interpretability, and predictive performance.</p>
<h3 id="encoding-categorical-features">Encoding Categorical Features</h3>
<p><code>Encoding</code> converts categorical values into numeric form so machine learning algorithms can utilize these features. Depending on the situation, you can choose:</p>
<ul>
<li><code>OneHotEncoder</code> for binary indicator features that represent each category separately.</li>
<li><code>LabelEncoder</code> for integer codes, though this may imply unintended order.</li>
<li><code>HashingEncoder</code> or frequency-based methods to handle high-cardinality features and control feature space size.</li>
</ul>
<p>After encoding, verify that the transformed features are meaningful and do not introduce artificial ordering.</p>
<h4 id="one-hot-encoding">One-Hot Encoding</h4>
<p><code>One-hot encoding</code> takes a categorical feature and converts it into a set of new binary features, where each binary feature corresponds to one possible category value. This process creates a set of indicator columns that hold <code>1</code> or <code>0</code>, indicating the presence or absence of a particular category in each row.</p>
<p>For example, consider the categorical feature <code>color</code>, which can take on the values <code>red</code>, <code>green</code>, or <code>blue</code>. In a dataset, you might have rows where <code>color</code> is <code>red</code> in one instance, <code>green</code> in another, and so on. By applying <code>one-hot encoding</code>, instead of keeping a single column with values like <code>red</code>, <code>green</code>, or <code>blue</code>, the encoding creates three new binary columns:</p>
<ul>
<li><code>color_red</code></li>
<li><code>color_green</code></li>
<li><code>color_blue</code></li>
</ul>
<p>Each of these new columns corresponds to one of the original categories. If a row had <code>color</code> set to <code>red</code>, the <code>color_red</code> column for that row would be <code>1</code>, and the other two columns (<code>color_green</code> and <code>color_blue</code>) would be <code>0</code>. Similarly, if <code>color</code> was originally <code>green</code>, then the <code>color_green</code> column would be <code>1</code>, while the <code>color_red</code> and <code>color_blue</code> columns would be <code>0</code>.</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/data_encoding.png" alt="Table showing one-hot encoding of colors: red, green, blue."></p>
<p>This approach prevents models from misinterpreting category values as numeric hierarchies. However, it can increase the number of features if a category has many unique values.</p>
<p>In this case, we are going to encode the <code>protocol</code> feature.</p>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.preprocessing <span class="hljs-built_in">import</span> OneHotEncoder

<span class="hljs-attr">encoder</span> = OneHotEncoder(<span class="hljs-attr">handle_unknown='ignore',</span> <span class="hljs-attr">sparse_output=False)</span>
<span class="hljs-attr">encoded</span> = encoder.fit_transform(df[['protocol']])

<span class="hljs-attr">encoded_df</span> = pd.DataFrame(encoded, <span class="hljs-attr">columns=encoder.get_feature_names_out(['protocol']))</span>
<span class="hljs-attr">df</span> = pd.concat([df.drop('protocol', <span class="hljs-attr">axis=1),</span> encoded_df], <span class="hljs-attr">axis=1)</span>
</code></pre>
<p>The original <code>protocol</code> feature is replaced with distinct binary columns, ensuring the model interprets each category independently.</p>
<h3 id="handling-skewed-data">Handling Skewed Data</h3>
<p>When a feature is <code>skewed</code>, its values are unevenly distributed, often with most observations clustered near one end and a few extreme values stretching out the distribution. Such skew can affect the performance of machine learning models, especially those sensitive to outliers or that assume more uniform or normal-like data distributions.</p>
<p><code>Scaling</code> or transforming these skewed features helps models better capture patterns in the data. One common transformation is applying a <code>log</code> transform to compress large values more than small ones, resulting in a more balanced distribution and less dominated by outliers. By doing this, models often gain improved stability, accuracy, and generalization ability.</p>
<p>Below, we show how to apply a <code>log</code> transform using the <code>log1p</code> function. This approach adds 1 to each value before taking the <code>log</code>, ensuring that the transform is defined even for values at or near zero.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-comment"># Apply logarithmic transformation to a skewed feature to reduce its skewness</span>
df[<span class="hljs-string">"bytes_transferred"</span>] = np.log1p(df[<span class="hljs-string">"bytes_transferred"</span>])  <span class="hljs-comment"># Add 1 to avoid log(0)</span>
</code></pre>
<p>The code above transforms the <code>bytes_transferred</code> feature. Before this transformation, the feature might have had a few very large values, overshadowing the majority of smaller observations. After the transformation, the distribution is evener, helping the model treat all data points fairly and reducing the risk of overfitting outliers.</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/log_histogram.png" alt="Two histograms: original distribution of bytes transferred and log-transformed distribution."></p>
<p>Visual comparisons of the distribution before and after the transform (as shown by the above figure) confirm that the original skew has been substantially reduced. Although no information is lost, the model now views the data through a lens that downplays extreme cases and highlights underlying patterns more clearly.</p>
<h3 id="data-splitting">Data Splitting</h3>
<p><code>Data splitting</code> involves dividing a dataset into three distinct subsets—<code>training</code>, <code>validation</code>, and <code>testing</code>—to ensure reliable model evaluation. By having separate sets, you can train your model on one subset, fine-tune it on another, and finally test its performance on data it has never seen before.</p>
<ul>
<li><code>Training Set</code>: Used to fit the model. Typically accounts for around 60-80% of the entire dataset.</li>
<li><code>Validation Set</code>: Used for tuning hyperparameters and model selection. Often around 10-20% of the entire dataset.</li>
<li><code>Test Set</code>: Used only after all model selections and tuning are complete. Often around 10-20% of the entire dataset.</li>
</ul>
<p>The code below demonstrates one approach using <code>train_test_split</code> from <code>scikit-learn</code>. The initial split allocates 80% of the data for training and 20% for testing. A subsequent split divides the 80% training portion into 60% for final training and 20% for validation.</p>
<p>Note that <code>test_size=0.25</code> in the second split refers to 25% of the previously created training subset (which is 80% of the data). In other words, <code>0.8 × 0.25 = 0.2</code> (20% of the entire dataset), leaving 60% for training and 20% for validation overall.</p>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.model_selection <span class="hljs-built_in">import</span> train_test_split

<span class="hljs-comment"># Separate features (X) and target (y)</span>
<span class="hljs-attr">X</span> = df.drop(<span class="hljs-string">"threat_level"</span>, <span class="hljs-attr">axis=1)</span>
<span class="hljs-attr">y</span> = df[<span class="hljs-string">"threat_level"</span>]

<span class="hljs-comment"># Initial split: 80% training, 20% testing</span>
X_train, X_test, y_train, <span class="hljs-attr">y_test</span> = train_test_split(X, y, <span class="hljs-attr">test_size=0.2,</span> <span class="hljs-attr">random_state=1337)</span>

<span class="hljs-comment"># Second split: from the 80% training portion, allocate 60% for final training and 20% for validation</span>
X_train, X_val, y_train, <span class="hljs-attr">y_val</span> = train_test_split(X_train, y_train, <span class="hljs-attr">test_size=0.25,</span> <span class="hljs-attr">random_state=1337)</span>
</code></pre>
<p>These subsets support a structured workflow:</p>
<ul>
<li>Train the model on <code>X_train</code> and <code>y_train</code>.</li>
<li>Tune hyperparameters or compare different models using <code>X_val</code> and <code>y_val</code>.</li>
<li>Finally, evaluate the performance on the untouched <code>X_test</code> and <code>y_test</code>.</li>
</ul>
<hr>
<h2 id="metrics-for-evaluating-a-model">Metrics for Evaluating a Model</h2>
<hr>
<p>When assessing a trained machine learning model, one examines a set of numerical metrics to gauge how well the model performs on a given task. These metrics often quantify the relationship between predictions and known ground-truth labels.</p>
<p>In the <a href="https://academy.hackthebox.com/module/details/290">Fundamentals of AI</a> module, we briefly covered metrics such as <code>accuracy</code>, <code>precision</code>, <code>recall</code>, and <code>F1-score</code>, and we know that these metrics provide different perspectives on model behavior.</p>
<h3 id="accuracy">Accuracy</h3>
<p><code>Accuracy</code> is the proportion of correct predictions out of all predictions made. It measures how often the model classifies instances correctly. A model with <code>accuracy: 0.9950</code> indicates that it makes correct predictions 99.50% of the time.</p>
<p>Key points about <code>accuracy</code>:</p>
<ul>
<li>Measures overall correctness.</li>
<li>Computed as <code>(true positives + true negatives) / (all instances)</code>.</li>
<li>May be misleading in cases of class imbalance.</li>
</ul>
<p>While <code>accuracy</code> appears intuitive, relying on it alone can hide important details. Consider a spam classification scenario where only 1% of incoming emails are spam and 99% are legitimate. A model that always predicts every email as legitimate will achieve <code>accuracy: 0.99</code>, but it will never catch any spam.</p>
<p>In this case, accuracy fails to highlight the model’s inability to correctly identify the minority class. This underscores the importance of complementary metrics, such as <code>precision</code>, <code>recall</code>, or <code>F1-score</code>, which provide a more nuanced understanding of performance when dealing with imbalanced datasets.</p>
<h3 id="precision">Precision</h3>
<p><code>Precision</code> measures how often the model’s predicted positives are truly positive. For <code>precision: 0.9949</code>, when the model labels an instance as positive, it is correct 99.49% of the time.</p>
<p>Key points about <code>precision</code>:</p>
<ul>
<li>Reflects quality of positive predictions.</li>
<li>Computed as <code>true positives / (true positives + false positives)</code>.</li>
<li>High <code>precision</code> reduces wasted effort caused by false alarms.</li>
</ul>
<p>With the spam classification example, if the model labels 100 emails as spam, and 99 of them are actually spam, then its <code>precision</code> is high. This reduces the inconvenience of losing important, legitimate emails to the spam folder. However, if the model rarely identifies spam in the first place, it may fail to catch a large portion of malicious emails. High <code>precision</code> alone does not guarantee that the model is finding all the spam it should.</p>
<h3 id="recall">Recall</h3>
<p><code>Recall</code> measures the model’s ability to identify all positive instances. For <code>recall: 0.9950</code>, the model detects 99.50% of all positives.</p>
<p>Key points about <code>recall</code>:</p>
<ul>
<li>Reflects completeness of positive detection.</li>
<li>Computed as <code>true positives / (true positives + false negatives)</code>.</li>
<li>High <code>recall</code> reduces the risk of missing critical cases.</li>
</ul>
<p>In the spam classification scenario, a model with high <code>recall</code> correctly flags most spam emails. This helps ensure that suspicious content does not slip through unnoticed. However, a model with very high <code>recall</code> but low <code>precision</code> might flood the spam folder with benign emails. Although it rarely misses spam, it inconveniences the user by misclassifying too many legitimate emails as spam.</p>
<h3 id="f1-score">F1-Score</h3>
<p><code>F1-score</code> is the harmonic mean of <code>precision</code> and <code>recall</code>. For <code>F1-score: 0.9949</code>, the metric indicates a near-perfect balance between these two aspects.</p>
<p>Key points about <code>F1-score</code>:</p>
<ul>
<li>Balances <code>precision</code> and <code>recall</code>.</li>
<li>Computed as <code>2 * (precision * recall) / (precision + recall)</code>.</li>
<li>Useful for tasks involving class imbalance.</li>
</ul>
<p>Continuing with the spam classification scenario, the <code>F1-score</code> ensures that the model not only minimizes the misclassification of legitimate emails (high <code>precision</code>) but also effectively identifies the majority of spam messages (high <code>recall</code>). By focusing on the balance rather than just one metric, the <code>F1-score</code> provides a more complete picture of the model’s performance in identifying and correctly handling both spam and non-spam emails.</p>
<h3 id="additional-considerations">Additional Considerations</h3>
<p>While these four metrics are common, other measures may provide further insights:</p>
<ul>
<li><code>Specificity</code>: Measures how effectively the model identifies negatives.</li>
<li><code>AUC</code>: The Area Under the ROC Curve, indicating the model’s discriminative capability at various thresholds.</li>
<li><code>Matthews Correlation Coefficient</code>: Useful for highly imbalanced datasets.</li>
<li><code>Confusion Matrix</code>: Summarizes predictions versus true labels, offering a comprehensive view of performance.</li>
</ul>
<p>Such metrics and visualizations help confirm that the given high values truly reflect robust performance, not just favorable conditions in the dataset.</p>
<h3 id="contextualizing-the-metrics">Contextualizing the Metrics</h3>
<p>When evaluating a model’s metrics (<code>accuracy: 0.9750</code>, <code>precision: 0.9300</code>, <code>recall: 0.9100</code>, <code>F1-score: 0.9200</code>), consider the following:</p>
<ul>
<li>Are these metrics consistent across different segments of the data?</li>
<li>Does the dataset represent real-world conditions, including the presence of class imbalances?</li>
<li>Are external factors, such as the cost of false positives or false negatives, properly accounted for?</li>
</ul>
<p>Even metrics that look impressive may not fully capture real-world performance if the dataset does not reflect operational conditions. For instance, high <code>accuracy</code> could be achieved if negative cases are heavily overrepresented, making it easier to appear correct by default. Verifying that both <code>precision</code> and <code>recall</code> remain robust helps ensure the model identifies important instances without becoming overwhelmed by incorrect predictions.</p>
<p>Depending on the setting, certain trade-offs emerge:</p>
<ul>
<li>In threat detection, a model might favor <code>recall</code> to avoid missing critical threats, even if it occasionally flags benign events.</li>
<li>In environments with limited resources, focusing on <code>precision</code> can reduce the burden caused by following up on false alarms.</li>
</ul>
<p>These metrics, considered together, provide a balanced perspective. The relatively high and reasonably aligned <code>precision</code> and <code>recall</code> values yield a strong <code>F1-score</code>, suggesting that the model performs consistently well across different classes. This balanced performance supports confidence that the model’s decisions are both reliable and meaningful in practice.</p>
<hr>
<h2 id="spam-classification">Spam Classification</h2>
<hr>
<p>Spam, or unsolicited bulk messaging, has been a persistent issue since the early days of digital communication. It clutters inboxes, poses security risks, and can be used for malicious purposes such as phishing attacks. Effective spam detection is crucial for maintaining the integrity and usability of email systems and other messaging platforms.</p>
<h3 id="naive-bayes-for-spam-detection">Naive Bayes for Spam Detection</h3>
<p>Bayes&#39; Theorem is a fundamental concept in probability theory that describes the probability of an event based on prior knowledge of conditions that might be related to the event. Mathematically, it is expressed as:</p>
<p>Code: python</p>
<pre><code class="lang-python">P<span class="hljs-comment">(A|B)</span> = <span class="hljs-comment">(P(B|A)</span> * P<span class="hljs-comment">(A)</span>) / P<span class="hljs-comment">(B)</span>
</code></pre>
<p>Where:</p>
<ul>
<li><code>P(A|B)</code> is the probability of event <code>A</code> occurring, given that <code>B</code> is true.</li>
<li><code>P(B|A)</code> is the probability of event <code>B</code> occurring, given that <code>A</code> is true.</li>
<li><code>P(A)</code> is the prior probability of event <code>A</code>.</li>
<li><code>P(B)</code> is the prior probability of event <code>B</code>.</li>
</ul>
<p>In the context of spam detection, <code>A</code> can represent the hypothesis that an email is spam (<code>Spam</code>), and <code>B</code> can represent the observed features of the email (e.g., words, phrases, etc.).</p>
<h4 id="applying-bayes-theorem-to-spam-detection">Applying Bayes&#39; Theorem to Spam Detection</h4>
<p>Let&#39;s break down how Bayes&#39; Theorem can be applied to determine if an email is spam:</p>
<ol>
<li><code>Hypothesis</code>: We want to determine the probability that an email is spam given its features.<ul>
<li><code>P(Spam|Features)</code>: Probability that an email is spam given its features.</li>
</ul>
</li>
<li><code>Likelihood</code>: This is the probability of observing the features given that the email is spam.<ul>
<li><code>P(Features|Spam)</code>: Probability of the features appearing in a spam email.</li>
</ul>
</li>
<li><code>Prior Probability</code>: The probability that any email is spam, irrespective of its features.<ul>
<li><code>P(Spam)</code>: Prior probability of an email being spam.</li>
</ul>
</li>
<li><code>Marginal Likelihood</code>: The total probability of observing the features, considering both spam and non-spam emails.<ul>
<li><code>P(Features)</code>: Probability of the features appearing in any email.</li>
</ul>
</li>
</ol>
<p>Using Bayes&#39; Theorem, we can express this as:</p>
<p>Code: python</p>
<pre><code class="lang-python">P<span class="hljs-comment">(Spam|Features)</span> = <span class="hljs-comment">(P(Features|Spam)</span> * P<span class="hljs-comment">(Spam)</span>) / P<span class="hljs-comment">(Features)</span>
</code></pre>
<h4 id="simplifying-with-naive-assumptions">Simplifying with Naive Assumptions</h4>
<p>Naive Bayes makes the &quot;naive&quot; assumption that the presence of a particular feature in an email is independent of the presence of any other feature, given the class label. This simplifies the calculation of <code>P(Features|Spam)</code>:</p>
<p>Code: python</p>
<pre><code class="lang-python">P(<span class="hljs-name">Features</span><span class="hljs-name">|Spam) = P(feature1|</span><span class="hljs-name">Spam</span>) * P(<span class="hljs-name">feature2</span><span class="hljs-name">|Spam) * ... * P(featureN|</span><span class="hljs-name">Spam</span>)
</code></pre>
<p>Similarly, for non-spam emails:</p>
<p>Code: python</p>
<pre><code class="lang-python">P(<span class="hljs-name">Features</span><span class="hljs-name">|Not Spam) = P(feature1|</span><span class="hljs-name">Not</span> Spam) * P(<span class="hljs-name">feature2</span><span class="hljs-name">|Not Spam) * ... * P(featureN|</span><span class="hljs-name">Not</span> Spam)
</code></pre>
<p>Using these probabilities, we can calculate the posterior probability of an email being spam or not spam given its features. The class with the higher posterior probability is chosen as the predicted class.</p>
<h4 id="example-calculation">Example Calculation</h4>
<p>Suppose we have an email with features <code>F1</code> and <code>F2</code>. We want to determine if this email is spam.</p>
<ul>
<li><code>P(Spam) = 0.3</code>: Prior probability that any email is spam.</li>
<li><code>P(Not Spam) = 0.7</code>: Prior probability that any email is not spam.</li>
<li><code>P(F1|Spam) = 0.4</code>: Probability of feature <code>F1</code> given the email is spam.</li>
<li><code>P(F2|Spam) = 0.5</code>: Probability of feature <code>F2</code> given the email is spam.</li>
<li><code>P(F1|Not Spam) = 0.2</code>: Probability of feature <code>F1</code> given the email is not spam.</li>
<li><code>P(F2|Not Spam) = 0.3</code>: Probability of feature <code>F2</code> given the email is not spam.</li>
</ul>
<p>Using the Naive Bayes assumption:</p>
<p>Code: python</p>
<pre><code class="lang-python">P(<span class="hljs-name">F1</span>, F2|Spam) = P(F1|Spam) * P(<span class="hljs-name">F2</span><span class="hljs-name">|Spam) = 0.4 * 0.5 = 0.2
P(F1, F2|</span><span class="hljs-name">Not</span> Spam) = P(<span class="hljs-name">F1</span><span class="hljs-name">|Not Spam) * P(F2|</span><span class="hljs-name">Not</span> Spam) = <span class="hljs-number">0.2</span> * <span class="hljs-number">0.3</span> = <span class="hljs-number">0.06</span>
</code></pre>
<p>Now, applying Bayes&#39; Theorem:</p>
<p>Code: python</p>
<pre><code class="lang-python">P<span class="hljs-comment">(Spam|F1, F2)</span> = <span class="hljs-comment">(P(F1, F2|Spam)</span> * P<span class="hljs-comment">(Spam)</span>) / P<span class="hljs-comment">(F1, F2)</span>
</code></pre>
<p>To find <code>P(F1, F2)</code>, we use the law of total probability:</p>
<p>Code: python</p>
<pre><code class="lang-python">P(<span class="hljs-name">F1</span>, F2) = P(<span class="hljs-name">F1</span>, F2|Spam) * P(Spam) + P(F1, F2|Not Spam) * P(<span class="hljs-name">Not</span> Spam)
          = (<span class="hljs-number">0.2</span> * 0.3) + (0.06 * <span class="hljs-number">0.7</span>)
          = <span class="hljs-number">0.06</span> + <span class="hljs-number">0.042</span>
          = <span class="hljs-number">0.102</span>
</code></pre>
<p>Thus:</p>
<p>Code: python</p>
<pre><code class="lang-python">P(Spam|F1, F2) = (<span class="hljs-number">0.2</span> * <span class="hljs-number">0.3</span>) / <span class="hljs-number">0.102</span>
               = <span class="hljs-number">0.06</span> / <span class="hljs-number">0.102</span>
               ≈ <span class="hljs-number">0.588</span>
</code></pre>
<p>Similarly:</p>
<p>Code: python</p>
<pre><code class="lang-python">P(Not Spam|F1, F2) = (P(F1, F2|Not Spam) * P(Not Spam)) / P(F1, F2)
                   = (<span class="hljs-number">0.06</span> * <span class="hljs-number">0.7</span>) / <span class="hljs-number">0.102</span>
                   = <span class="hljs-number">0.042</span> / <span class="hljs-number">0.102</span>
                   ≈ <span class="hljs-number">0.412</span>
</code></pre>
<p>Since <code>P(Spam|F1, F2) &gt; P(Not Spam|F1, F2)</code>, the email is classified as spam.</p>
<hr>
<h2 id="the-spam-dataset">The Spam Dataset</h2>
<hr>
<p>We&#39;ll explore Bayesian spam classification using the <a href="https://archive.ics.uci.edu/dataset/228/sms+spam+collection">SMS Spam Collection dataset</a>, a curated resource tailored for developing and evaluating text-based spam filters. This dataset emerges from the combined efforts of Tiago A. Almeida and Akebo Yamakami at the School of Electrical and Computer Engineering at the University of Campinas in Brazil, and José María Gómez Hidalgo at the R\&amp;D Department of Optenet in Spain.</p>
<p>Their work, &quot;<code>Contributions to the Study of SMS Spam Filtering: New Collection and Results</code>,&quot; presented at the 2011 ACM Symposium on Document Engineering, aimed to address the growing problem of unsolicited mobile phone messages, commonly known as <code>SMS spam</code>. Recognizing that many existing spam filtering resources focused on email rather than text messages, the authors assembled this dataset from multiple sources, including the Grumbletext website, the NUS SMS Corpus, and Caroline Tag’s PhD thesis.</p>
<p>The resulting corpus contains 5,574 text messages annotated as either <code>ham</code> (legitimate) or <code>spam</code> (unwanted), making it a great resource for building and testing models that can differentiate meaningful communications from intrusive or deceptive ones. In this context, <code>ham</code> refers to messages from known contacts, subscriptions, or newsletters that hold value for the recipient, while <code>spam</code> represents unsolicited content that typically offers no benefit and may even pose risks to the user.</p>
<h3 id="downloading-the-dataset">Downloading the Dataset</h3>
<p>The first step in our process is to download this dataset, and we&#39;ll do it programmatically in our notebook.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-built_in">import</span> requests
<span class="hljs-built_in">import</span> zipfile
<span class="hljs-built_in">import</span> io

<span class="hljs-comment"># URL of the dataset</span>
<span class="hljs-attr">url</span> = <span class="hljs-string">"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip"</span>
<span class="hljs-comment"># Download the dataset</span>
<span class="hljs-attr">response</span> = requests.get(url)
<span class="hljs-keyword">if</span> response.<span class="hljs-attr">status_code</span> == <span class="hljs-number">200</span>:
    print(<span class="hljs-string">"Download successful"</span>)
<span class="hljs-keyword">else</span>:
    print(<span class="hljs-string">"Failed to download the dataset"</span>)
</code></pre>
<p>We use the <code>requests</code> library to send an HTTP GET request to the URL of the dataset. We check the status code of the response to determine if the download was successful (<code>status_code == 200</code>).</p>
<p>After downloading the dataset, we need to extract its contents. The dataset is provided in a <code>.zip</code> file format, which we will handle using Python&#39;s <code>zipfile</code> and <code>io</code> libraries.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Extract the dataset</span>
<span class="hljs-keyword">with</span> zipfile.ZipFile(io.BytesIO(response.content)) <span class="hljs-keyword">as</span> z:
    z.extractall(<span class="hljs-string">"sms_spam_collection"</span>)
    print(<span class="hljs-string">"Extraction successful"</span>)
</code></pre>
<p>Here, <code>response.content</code> contains the binary data of the downloaded <code>.zip</code> file. We use <code>io.BytesIO</code> to convert this binary data into a bytes-like object that can be processed by <code>zipfile.ZipFile</code>. The <code>extractall</code> method extracts all files from the archive into a specified directory, in this case, <code>sms_spam_collection</code>.</p>
<p>It&#39;s useful to verify that the extraction was successful and to see what files were extracted.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> os

<span class="hljs-comment"># List the extracted files</span>
extracted_files = os.listdir(<span class="hljs-string">"sms_spam_collection"</span>)
<span class="hljs-keyword">print</span>(<span class="hljs-string">"Extracted files:"</span>, extracted_files)
</code></pre>
<p>The <code>os.listdir</code> function lists all files and directories in the specified path, allowing us to confirm that the <code>SMSSpamCollection</code> file is present.</p>
<h3 id="loading-the-dataset">Loading the Dataset</h3>
<p>With the dataset extracted, we can now load it into a <code>pandas</code> DataFrame for further analysis. The SMS Spam Collection dataset is stored in a tab-separated values (TSV) file format, which we specify using the <code>sep</code> parameter in <code>pd.read_csv</code>.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-built_in">import</span> pandas as pd

<span class="hljs-comment"># Load the dataset</span>
<span class="hljs-attr">df</span> = pd.read_csv(
    <span class="hljs-string">"sms_spam_collection/SMSSpamCollection"</span>,
    <span class="hljs-attr">sep="\t",</span>
    <span class="hljs-attr">header=None,</span>
    <span class="hljs-attr">names=["label",</span> <span class="hljs-string">"message"</span>],
)
</code></pre>
<p>Here, we specify that the file is tab-separated (<code>sep=&quot;\t&quot;</code>), and since the file does not contain a header row, we set <code>header=None</code> and provide column names manually using the <code>names</code> parameter.</p>
<p>After loading the dataset, it is important to inspect it for basic information, missing values, and duplicates. This helps ensure that the data is clean and ready for analysis.</p>
<p>Code: python</p>
<pre><code class="lang-python"># Display basic information about the dataset
print(<span class="hljs-string">"-------------------- HEAD --------------------"</span>)
print(<span class="hljs-name">df</span>.head())
print(<span class="hljs-string">"-------------------- DESCRIBE --------------------"</span>)
print(<span class="hljs-name">df</span>.describe())
print(<span class="hljs-string">"-------------------- INFO --------------------"</span>)
print(<span class="hljs-name">df</span>.info())
</code></pre>
<p>To get an overview of the dataset, we can use the <code>head</code>, <code>describe</code>, and info <code>methods</code> provided by pandas.</p>
<ul>
<li><code>df.head()</code> displays the first few rows of the DataFrame, giving us a quick look at the data.</li>
<li><code>df.describe()</code> provides a statistical summary of the numerical columns in the DataFrame. Although our dataset is primarily text-based, this can still be useful for understanding the distribution of labels.</li>
<li><code>df.info()</code> gives a concise summary of the DataFrame, including the number of non-null entries and the data types of each column.</li>
</ul>
<p>Checking for missing values is crucial to ensure that our dataset does not contain any incomplete entries.</p>
<p>Code: python</p>
<pre><code class="lang-python"># Check <span class="hljs-keyword">for</span> missing <span class="hljs-built_in">values</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Missing values:\n"</span>, df.isnull().<span class="hljs-built_in">sum</span>())
</code></pre>
<p>The <code>isnull</code> method returns a DataFrame of the same shape as the original, with boolean values indicating whether each entry is null. The <code>sum</code> method then counts the number of <code>True</code> values in each column, giving us the total number of missing entries.</p>
<p>Duplicate entries can skew the results of our analysis, so it&#39;s important to identify and remove them.</p>
<p>Code: python</p>
<pre><code class="lang-python"># Check <span class="hljs-keyword">for</span> <span class="hljs-keyword">duplicates</span>
<span class="hljs-keyword">print</span>(<span class="hljs-string">"Duplicate entries:"</span>, df.duplicated().<span class="hljs-built_in">sum</span>())

# Remove <span class="hljs-keyword">duplicates</span> <span class="hljs-keyword">if</span> any
df = df.drop_duplicates()
</code></pre>
<p>The <code>duplicated</code> method returns a boolean Series indicating whether each row is a duplicate or not. The <code>sum</code> method counts the number of <code>True</code> values, giving us the total number of duplicate entries. We then use the <code>drop_duplicates</code> method to remove these duplicates from the DataFrame.</p>
<hr>
<h2 id="preprocessing-the-spam-dataset">Preprocessing the Spam Dataset</h2>
<hr>
<p>After loading the SMS Spam Collection dataset, the next step is preprocessing the text data. Preprocessing standardizes the text, reduces noise, and extracts meaningful features, all of which improve the performance of the Bayes spam classifier. The steps outlined here rely on the <code>nltk</code> library for tasks such as tokenization, stop word removal, and stemming.</p>
<p>Before processing any text, you must download the required NLTK data files. These include <code>punkt</code> for tokenization and <code>stopwords</code> for removing common words that do not contribute to meaning. Ensuring all required resources are available at this stage prevents interruptions during later processing steps.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> nltk

<span class="hljs-comment"># Download the necessary NLTK data files</span>
nltk.download(<span class="hljs-string">"punkt"</span>)
nltk.download(<span class="hljs-string">"punkt_tab"</span>)
nltk.download(<span class="hljs-string">"stopwords"</span>)

<span class="hljs-keyword">print</span>(<span class="hljs-string">"=== BEFORE ANY PREPROCESSING ==="</span>) 
<span class="hljs-keyword">print</span>(df.head(<span class="hljs-number">5</span>))
</code></pre>
<h4 id="lowercasing-the-text">Lowercasing the Text</h4>
<p><code>Lowercasing the text</code> ensures that the classifier treats words equally, regardless of their original casing. By converting all characters to lowercase, the model considers &quot;<code>Free</code>&quot; and &quot;<code>free</code>&quot; as the <code>same token</code>, effectively reducing dimensionality and improving consistency.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-meta"># Convert all message text to lowercase</span>
df[<span class="hljs-string">"message"</span>] = df[<span class="hljs-string">"message"</span>].str.<span class="hljs-built_in">lower</span>()
<span class="hljs-keyword">print</span>(<span class="hljs-string">"\n=== AFTER LOWERCASING ==="</span>)
<span class="hljs-keyword">print</span>(df[<span class="hljs-string">"message"</span>].head(<span class="hljs-number">5</span>))
</code></pre>
<p>After this step, the <code>dataset contains uniformly cased text</code>, preventing the model from assigning different weights to tokens that differ only by letter case.</p>
<h3 id="removing-punctuation-and-numbers">Removing Punctuation and Numbers</h3>
<p><code>Removing unnecessary punctuation and numbers</code> simplifies the dataset by focusing on meaningful words. However, certain symbols such as <code>$</code> and <code>!</code> may contain important context in spam messages. For example, <code>$</code> might indicate a monetary amount, and <code>!</code> might add emphasis.</p>
<p>The code below removes all characters other than lowercase letters, whitespace, dollar signs, or exclamation marks. This balance between cleaning the data and preserving important symbols helps the model concentrate on features relevant to distinguishing spam from ham messages.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> re

<span class="hljs-comment"># Remove non-essential punctuation and numbers, keep useful symbols like $ and !</span>
df[<span class="hljs-string">"message"</span>] = df[<span class="hljs-string">"message"</span>].apply(<span class="hljs-keyword">lambda</span> x: re.sub(<span class="hljs-string">r"[^a-z\s$!]"</span>, <span class="hljs-string">""</span>, x))
print(<span class="hljs-string">"\n=== AFTER REMOVING PUNCTUATION &amp; NUMBERS (except $ and !) ==="</span>)
print(df[<span class="hljs-string">"message"</span>].head(<span class="hljs-number">5</span>))
</code></pre>
<p>After this step, the text is cleaner, more uniform, and better suited for subsequent preprocessing tasks such as tokenization, stop word removal, or stemming.</p>
<h3 id="tokenizing-the-text">Tokenizing the Text</h3>
<p><code>Tokenization</code> divides the message text into individual words or tokens, a crucial step before further analysis. By converting unstructured text into a sequence of words, we prepare the data for operations like removing stop words and applying stemming. <code>Each token corresponds to a meaningful unit</code>, allowing downstream processes to operate on smaller, standardized elements rather than entire sentences.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> nltk.<span class="hljs-keyword">tokenize</span> <span class="hljs-keyword">import</span> word_tokenize

# Split <span class="hljs-keyword">each</span> message <span class="hljs-keyword">into</span> individual tokens
df[<span class="hljs-string">"message"</span>] = df[<span class="hljs-string">"message"</span>].apply(word_tokenize)
<span class="hljs-keyword">print</span>(<span class="hljs-string">"\n=== AFTER TOKENIZATION ==="</span>)
<span class="hljs-keyword">print</span>(df[<span class="hljs-string">"message"</span>].head(<span class="hljs-number">5</span>))
</code></pre>
<p>Once tokenized, the dataset contains messages represented as lists of words, ready for additional preprocessing steps that further refine the text data.</p>
<h3 id="removing-stop-words">Removing Stop Words</h3>
<p><code>Stop words</code> are common words like <code>and</code>, <code>the</code>, or <code>is</code> that often do not add meaningful context. Removing them reduces noise and focuses the model on the words most likely to help distinguish spam from ham messages. By reducing the number of non-informative tokens, we help the model learn more efficiently.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> nltk.corpus import stopwords

<span class="hljs-comment"># Define a set of English stop words and remove them from the tokens</span>
stop_words = <span class="hljs-keyword">set</span>(stopwords.<span class="hljs-built_in">words</span>(<span class="hljs-string">"english"</span>))
df[<span class="hljs-string">"message"</span>] = df[<span class="hljs-string">"message"</span>].apply(lambda x: [<span class="hljs-built_in">word</span> <span class="hljs-keyword">for</span> <span class="hljs-built_in">word</span> <span class="hljs-keyword">in</span> x <span class="hljs-keyword">if</span> <span class="hljs-built_in">word</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words])
print(<span class="hljs-string">"\n=== AFTER REMOVING STOP WORDS ==="</span>)
print(df[<span class="hljs-string">"message"</span>].head(<span class="hljs-number">5</span>))
</code></pre>
<p>The token lists are shorter at this stage and contain fewer non-informative words, setting a cleaner stage for future text transformations.</p>
<h3 id="stemming">Stemming</h3>
<p><code>Stemming</code> normalizes words by reducing them to their base form (e.g., <code>running</code> becomes <code>run</code>). This consolidates different forms of the same root word, effectively cutting the vocabulary size and smoothing out the text representation. As a result, the model can better understand the underlying concepts without being distracted by trivial variations in word forms.</p>
<p>Code: python</p>
<pre><code class="lang-python">from nltk.<span class="hljs-keyword">stem</span> import PorterStemmer

# <span class="hljs-keyword">Stem</span> each <span class="hljs-keyword">token</span> to reduce words to their base <span class="hljs-keyword">form</span>
stemmer = PorterStemmer()
df[<span class="hljs-string">"message"</span>] = df[<span class="hljs-string">"message"</span>].apply(lambda x: [stemmer.<span class="hljs-keyword">stem</span>(word) <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> x])
<span class="hljs-keyword">print</span>(<span class="hljs-string">"\n=== AFTER STEMMING ==="</span>)
<span class="hljs-keyword">print</span>(df[<span class="hljs-string">"message"</span>].head(5))
</code></pre>
<p>After stemming, the token lists focus on root word forms, further simplifying the text and improving the model’s generalization ability.</p>
<h3 id="joining-tokens-back-into-a-single-string">Joining Tokens Back into a Single String</h3>
<p>While tokens are useful for manipulation, many machine-learning algorithms and vectorization techniques (e.g., TF-IDF) work best with raw text strings. Rejoining the tokens into a space-separated string restores a format compatible with these methods, allowing the dataset to move seamlessly into the feature extraction phase.</p>
<p>Code: python</p>
<pre><code class="lang-python"># Rejoin <span class="hljs-built_in">tokens</span> into a single <span class="hljs-built_in">string</span> <span class="hljs-keyword">for</span> <span class="hljs-built_in">feature</span> extraction
df[<span class="hljs-string">"message"</span>] = df[<span class="hljs-string">"message"</span>].<span class="hljs-built_in">apply</span>(<span class="hljs-built_in">lambda</span> x: <span class="hljs-string">" "</span>.<span class="hljs-built_in">join</span>(x))
<span class="hljs-built_in">print</span>(<span class="hljs-string">"\n=== AFTER JOINING TOKENS BACK INTO STRINGS ==="</span>)
<span class="hljs-built_in">print</span>(df[<span class="hljs-string">"message"</span>].head(<span class="hljs-number">5</span>))
</code></pre>
<p>At this point, the messages are fully preprocessed. Each message is a cleaned, normalized string ready for vectorization and subsequent model training, ultimately improving the classifier’s performance.</p>
<hr>
<h2 id="feature-extraction">Feature Extraction</h2>
<hr>
<p><code>Feature extraction</code> transforms preprocessed SMS messages into numerical vectors suitable for machine learning algorithms. Since models <code>cannot directly process raw text data</code>, they rely on numeric representations—such as counts or frequencies of words—to identify patterns that differentiate spam from ham.</p>
<h3 id="representing-text-as-numerical-features">Representing Text as Numerical Features</h3>
<p>A common way to represent text numerically is through a <code>bag-of-words</code> model. This technique constructs a vocabulary of unique terms from the dataset and represents each message as a vector of term counts. Each element in the vector corresponds to a term in the vocabulary, and its value indicates how often that term appears in the message.</p>
<p>Using only <code>unigrams</code> (individual words) does not preserve the original word order; it treats each document as a collection of terms and their frequencies, independent of sequence.</p>
<p>To introduce a limited sense of order, we also include <code>bigrams</code>, which are pairs of consecutive words. By incorporating bigrams, we capture some local ordering information.</p>
<p>For example, the bigram <code>free prize</code> might help distinguish a spam message promising a reward from a simple statement containing the word <code>free</code> alone. However, beyond these small sequences, the global order of words and sentence structure remains largely lost. In other words, <code>CountVectorizer</code> does not preserve complete word order; it only captures localized patterns defined by the chosen <code>ngram_range</code>.</p>
<h3 id="using-countvectorizer-for-the-bag-of-words-approach">Using CountVectorizer for the Bag-of-Words Approach</h3>
<p><code>CountVectorizer</code> from the <code>scikit-learn</code> library efficiently implements the bag-of-words approach. It converts a collection of documents into a matrix of term counts, where each row represents a message and each column corresponds to a term (unigram or bigram). Before transformation, <code>CountVectorizer</code> applies tokenization, builds a vocabulary, and then maps each document to a numeric vector.</p>
<p>Key parameters for refining the feature set:</p>
<ul>
<li><code>min_df=1</code>: A term must appear in at least one document to be included. While this threshold is set to <code>1</code> here, higher values can be used in practice to exclude rare terms.</li>
<li><code>max_df=0.9</code>: Terms that appear in more than 90% of the documents are excluded, removing overly common words that provide limited differentiation.</li>
<li><code>ngram_range=(1, 2)</code>: The feature matrix captures individual words and common word pairs by including unigrams and bigrams, potentially improving the model’s ability to detect spam patterns.</li>
</ul>
<p>Code: python</p>
<pre><code class="lang-python">from sklearn.feature_extraction.text <span class="hljs-built_in">import</span> CountVectorizer

<span class="hljs-comment"># Initialize CountVectorizer with bigrams, min_df, and max_df to focus on relevant terms</span>
<span class="hljs-attr">vectorizer</span> = CountVectorizer(<span class="hljs-attr">min_df=1,</span> <span class="hljs-attr">max_df=0.9,</span> <span class="hljs-attr">ngram_range=(1,</span> <span class="hljs-number">2</span>))

<span class="hljs-comment"># Fit and transform the message column</span>
<span class="hljs-attr">X</span> = vectorizer.fit_transform(df[<span class="hljs-string">"message"</span>])

<span class="hljs-comment"># Labels (target variable)</span>
<span class="hljs-attr">y</span> = df[<span class="hljs-string">"label"</span>].apply(lambda x: <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> <span class="hljs-attr">x</span> == <span class="hljs-string">"spam"</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)  <span class="hljs-comment"># Converting labels to 1 and 0</span>
</code></pre>
<p>After this step, <code>X</code> becomes a numerical feature matrix ready to be fed into a classifier, such as Naive Bayes.</p>
<h4 id="how-countvectorizer-works">How CountVectorizer Works</h4>
<p><code>CountVectorizer</code> operates in three main stages:</p>
<ol>
<li><code>Tokenization</code>: Splits the text into tokens based on the specified <code>ngram_range</code>. For <code>ngram_range=(1, 2)</code>, it extracts both unigrams (like &quot;<code>message</code>&quot;) and bigrams (like &quot;<code>free prize</code>&quot;).</li>
<li><code>Building the Vocabulary</code>: Uses <code>min_df</code> and <code>max_df</code> to decide which terms to include. Terms that are too rare or common are filtered out, leaving a vocabulary that balances informative and distinctive terms.</li>
<li><code>Vectorization</code>: Transforms each document into a vector of term counts. Each vector entry corresponds to a term from the vocabulary, and its value represents how many times that term appears in the document.</li>
</ol>
<h4 id="example-with-unigrams">Example with Unigrams</h4>
<p>Consider five documents:</p>
<ol>
<li><code>The free prize is waiting for you</code></li>
<li><code>The spam message offers a free prize now</code></li>
<li><code>The spam filter might detect this</code></li>
<li><code>The important news says you won a free trip</code></li>
<li><code>The message truly is important</code></li>
</ol>
<p>If we use <code>ngram_range=(1, 1)</code> (unigrams only) and <code>min_df=1</code>, <code>max_df=0.9</code>, the word <code>The</code> will be removed from unigram vocabulary by <code>max_df=0.9</code> since it appears more than 90% in the documents, leaving the below unigram matrix:</p>
<table>
<thead>
<tr>
<th>Document</th>
<th>free</th>
<th>prize</th>
<th>is</th>
<th>waiting</th>
<th>for</th>
<th>you</th>
<th>spam</th>
<th>message</th>
<th>offers</th>
<th>a</th>
<th>now</th>
<th>filter</th>
<th>might</th>
<th>detect</th>
<th>this</th>
<th>important</th>
<th>news</th>
<th>says</th>
<th>won</th>
<th>trip</th>
<th>truly</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>5</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<h4 id="example-with-bigrams">Example with Bigrams</h4>
<p>Using <code>ngram_range=(1, 2)</code>, the final vocabulary includes all of the above unigrams and any valid bigrams containing those unigrams. For instance, <code>free prize</code> occurs in Documents 1 and 2. The resulting matrix provides additional context, helping the model differentiate messages more effectively:</p>
<table>
<thead>
<tr>
<th>Document</th>
<th>free</th>
<th>prize</th>
<th>is</th>
<th>waiting</th>
<th>for</th>
<th>you</th>
<th>spam</th>
<th>message</th>
<th>offers</th>
<th>a</th>
<th>now</th>
<th>filter</th>
<th>might</th>
<th>detect</th>
<th>this</th>
<th>important</th>
<th>news</th>
<th>says</th>
<th>won</th>
<th>trip</th>
<th>truly</th>
<th>free prize</th>
<th>prize is</th>
<th>is waiting</th>
<th>waiting for</th>
<th>for you</th>
<th>spam message</th>
<th>message offers</th>
<th>offers a</th>
<th>a free</th>
<th>prize now</th>
<th>spam filter</th>
<th>filter might</th>
<th>might detect</th>
<th>detect this</th>
<th>important news</th>
<th>news says</th>
<th>says you</th>
<th>you won</th>
<th>won a</th>
<th>free trip</th>
<th>message truly</th>
<th>truly is</th>
<th>is important</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>5</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>This feature extraction process, using <code>CountVectorizer</code>, has transformed our text data into a resulting matrix provides a concise, numerical representation of each message, ready for training a classification model.</p>
<hr>
<h2 id="training-and-evaluation-spam-detection-">Training and Evaluation (Spam Detection)</h2>
<hr>
<h3 id="training">Training</h3>
<p>After preprocessing the text data and extracting meaningful features, we train a machine-learning model for spam detection. We use the <code>Multinomial Naive Bayes</code> classifier, which is well-suited for text classification tasks due to its probabilistic nature and ability to efficiently handle large, sparse feature sets.</p>
<p>To streamline the entire process, we employ a <code>Pipeline</code>. A pipeline chains together the vectorization and modeling steps, ensuring that the same data transformation (in this case, <code>CountVectorizer</code>) is consistently applied before feeding the transformed data into the classifier. This approach simplifies both development and maintenance by encapsulating the feature extraction and model training into a single, unified workflow.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-symbol">from</span> sklearn.model_selection <span class="hljs-meta">import</span> train_test_split, GridSearchCV
<span class="hljs-symbol">from</span> sklearn.naive_bayes <span class="hljs-meta">import</span> <span class="hljs-keyword">MultinomialNB
</span><span class="hljs-symbol">from</span> sklearn.pipeline <span class="hljs-meta">import</span> Pipeline

# <span class="hljs-keyword">Build </span>the pipeline <span class="hljs-keyword">by </span>combining vectorization <span class="hljs-keyword">and </span>classification
<span class="hljs-symbol">pipeline</span> = Pipeline([
    (<span class="hljs-string">"vectorizer"</span>, vectorizer),
    (<span class="hljs-string">"classifier"</span>, <span class="hljs-keyword">MultinomialNB())
</span>])
</code></pre>
<p>With the pipeline in place, we can easily integrate hyperparameter tuning to improve model performance. The objective is to find optimal parameter values for the classifier, ensuring that the model generalizes well and avoids overfitting.</p>
<p>To achieve this, we use <code>GridSearchCV</code>. This method systematically searches through specified hyperparameter values to identify the configuration that produces the best performance. In the case of <code>MultinomialNB</code>, we focus on the <code>alpha</code> parameter, a smoothing factor that adjusts how the model handles unseen words and prevents probabilities from being zero. We can balance bias and variance by tuning <code>alpha</code>, ultimately improving the model’s robustness.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Define the parameter grid for hyperparameter tuning</span>
<span class="hljs-attr">param_grid</span> = {
    <span class="hljs-string">"classifier__alpha"</span>: [<span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.15</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.25</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.75</span>, <span class="hljs-number">1.0</span>]
}

<span class="hljs-comment"># Perform the grid search with 5-fold cross-validation and the F1-score as metric</span>
<span class="hljs-attr">grid_search</span> = GridSearchCV(
    pipeline,
    param_grid,
    <span class="hljs-attr">cv=5,</span>
    <span class="hljs-attr">scoring="f1"</span>
)

<span class="hljs-comment"># Fit the grid search on the full dataset</span>
grid_search.fit(df[<span class="hljs-string">"message"</span>], y)

<span class="hljs-comment"># Extract the best model identified by the grid search</span>
<span class="hljs-attr">best_model</span> = grid_search.best_estimator_
print(<span class="hljs-string">"Best model parameters:"</span>, grid_search.best_params_)
</code></pre>
<p>The combination of <code>Pipeline</code> and <code>GridSearchCV</code> ensures a clean, consistent workflow. First, <code>CountVectorizer</code> converts raw text into numeric features suitable for the classifier. Next, <code>MultinomialNB</code> applies its probabilistic principles to distinguish between spam and ham messages.</p>
<p>Finally, by evaluating <code>alpha</code> values and leveraging cross-validation, we reliably select the best configuration based on the F1-score, a balanced metric for precision and recall.</p>
<h3 id="evaluation">Evaluation</h3>
<p><img src="https://academy.hackthebox.com/storage/modules/292/spam_eval.png" alt="Confusion matrix for spam classifier: 889 true negatives, 5 false positives, 0 false negatives, 140 true positives."></p>
<p>After training and fine-tuning the spam detection model, assessing its performance on new, unseen SMS messages is critical. This evaluation helps verify how well the model generalizes to real-world data and highlights improvement areas. The evaluation mirrors the preprocessing and feature extraction steps applied during training, ensuring a consistent and fair assessment of the model’s true predictive capabilities.</p>
<h4 id="setting-up-the-evaluation-messages">Setting Up the Evaluation Messages</h4>
<p>We begin by providing a list of new SMS messages for evaluation. These messages represent the types of inputs the model might receive in real-world use, including promotional offers, routine communications, urgent alerts, reminders, and incentive-based spam.</p>
<p>Code: python</p>
<pre><code class="lang-python"># <span class="hljs-type">Example</span> <span class="hljs-type">SMS</span> messages for evaluation
new_messages = [
    <span class="hljs-comment">"Congratulations! You've won a $1000 Walmart gift card. Go to http://bit.ly/1234 to claim now."</span>,
    <span class="hljs-comment">"Hey, are we still meeting up for lunch today?"</span>,
    <span class="hljs-comment">"Urgent! Your account has been compromised. Verify your details here: www.fakebank.com/verify"</span>,
    <span class="hljs-comment">"Reminder: Your appointment is scheduled for tomorrow at 10am."</span>,
    <span class="hljs-comment">"FREE entry in a weekly competition to win an iPad. Just text WIN to 80085 now!"</span>,
]
</code></pre>
<h4 id="preprocessing-new-messages">Preprocessing New Messages</h4>
<p>Before predicting with the trained model, we must preprocess the new messages using the same steps applied during training. Consistent preprocessing ensures that the model receives data in the same format it was trained on. The <code>preprocess_message</code> function converts each message to lowercase, removes non-alphabetic characters, tokenizes the text, removes stop words, and applies stemming.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> re

<span class="hljs-comment"># Preprocess function that mirrors the training-time preprocessing</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocess_message</span><span class="hljs-params">(message)</span>:</span>
    message = message.lower()
    message = re.sub(<span class="hljs-string">r"[^a-z\s$!]"</span>, <span class="hljs-string">""</span>, message)
    tokens = word_tokenize(message)
    tokens = [word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words]
    tokens = [stemmer.stem(word) <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> tokens]
    <span class="hljs-keyword">return</span> <span class="hljs-string">" "</span>.join(tokens)
</code></pre>
<p>Next, we apply this function to each of the new messages:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-meta"># Preprocess and vectorize messages</span>
processed_messages = [preprocess_message(msg) <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> <span class="hljs-keyword">new</span><span class="hljs-type">_messages</span>]
</code></pre>
<h4 id="vectorizing-the-processed-messages">Vectorizing the Processed Messages</h4>
<p>The model expects numerical input features. To achieve this, we apply the same vectorization method used during training. The <code>CountVectorizer</code> saved within the pipeline (<code>best_model.named_steps[&quot;vectorizer&quot;]</code>) transforms the preprocessed text into a numerical feature matrix.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Transform preprocessed messages into feature vectors</span>
<span class="hljs-attr">X_new</span> = best_model.named_steps[<span class="hljs-string">"vectorizer"</span>].transform(processed_messages)
</code></pre>
<h4 id="making-predictions">Making Predictions</h4>
<p>With the data properly preprocessed and vectorized, we feed the new messages into the trained <code>MultinomialNB</code> classifier (<code>best_model.named_steps[&quot;classifier&quot;]</code>). This classifier outputs both a predicted label (spam or not spam) and class probabilities, indicating the model’s confidence in its decision.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Predict with the trained classifier</span>
<span class="hljs-attr">predictions</span> = best_model.named_steps[<span class="hljs-string">"classifier"</span>].predict(X_new)
<span class="hljs-attr">prediction_probabilities</span> = best_model.named_steps[<span class="hljs-string">"classifier"</span>].predict_proba(X_new)
</code></pre>
<h4 id="displaying-predictions-and-probabilities">Displaying Predictions and Probabilities</h4>
<p>The next step is to present the evaluation results. For each message, we display:</p>
<ul>
<li>The original text of the message.</li>
<li>The predicted label (<code>Spam</code> or <code>Not-Spam</code>).</li>
<li>The probability that the message is spam.</li>
<li>The probability that the message is not spam.</li>
</ul>
<p>This output provides insight into the model’s reasoning and confidence levels, making it easier to understand and trust the predictions.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Display predictions and probabilities for each evaluated message</span>
<span class="hljs-keyword">for</span> i, msg <span class="hljs-keyword">in</span> enumerate(new_messages):
    prediction = <span class="hljs-string">"Spam"</span> <span class="hljs-keyword">if</span> predictions[i] == 1 <span class="hljs-keyword">else</span> <span class="hljs-string">"Not-Spam"</span>
    spam_probability = prediction_probabilities[i][1]  <span class="hljs-comment"># Probability of being spam</span>
    ham_probability = prediction_probabilities[i][0]   <span class="hljs-comment"># Probability of being not spam</span>

    <span class="hljs-built_in">print</span>(f<span class="hljs-string">"Message: {msg}"</span>)
    <span class="hljs-built_in">print</span>(f<span class="hljs-string">"Prediction: {prediction}"</span>)
    <span class="hljs-built_in">print</span>(f<span class="hljs-string">"Spam Probability: {spam_probability:.2f}"</span>)
    <span class="hljs-built_in">print</span>(f<span class="hljs-string">"Not-Spam Probability: {ham_probability:.2f}"</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"-"</span> * 50)
</code></pre>
<p>A representative output might look like this:</p>
<p>Code: txt</p>
<pre><code class="lang-txt">Message: Congratulations! You've won a $1000 Walmart gift card. Go to http://bit.ly/1234 to claim now.
Prediction: Spam
Spam Probability: 1.00
<span class="hljs-section">Not-Spam Probability: 0.00
--------------------------------------------------</span>
Message: Hey, are we still meeting up for lunch today?
Prediction: Not-Spam
Spam Probability: 0.00
<span class="hljs-section">Not-Spam Probability: 1.00
--------------------------------------------------</span>
Message: Urgent! Your account has been compromised. Verify your details here: www.fakebank.com/verify
Prediction: Spam
Spam Probability: 0.94
<span class="hljs-section">Not-Spam Probability: 0.06
--------------------------------------------------</span>
Message: Reminder: Your appointment is scheduled for tomorrow at 10am.
Prediction: Not-Spam
Spam Probability: 0.00
<span class="hljs-section">Not-Spam Probability: 1.00
--------------------------------------------------</span>
Message: FREE entry in a weekly competition to win an iPad. Just text WIN to 80085 now!
Prediction: Spam
Spam Probability: 1.00
<span class="hljs-section">Not-Spam Probability: 0.00
--------------------------------------------------</span>
</code></pre>
<p>These results show that the model can differentiate between benign messages and a range of spam content, providing both a categorical decision and the underlying probability estimates.</p>
<h4 id="using-joblib-for-saving-models">Using joblib for Saving Models</h4>
<p>After confirming satisfactory performance, preserving the trained model to be reused later is often necessary. By saving the model to a file, users can avoid the computational expense of retraining it from scratch each time. This is especially helpful in production environments where quick predictions are required.</p>
<p><code>joblib</code> is a Python library designed to efficiently serialize and deserialize Python objects, particularly those containing large arrays such as NumPy arrays or scikit-learn models. <code>Serialization</code> converts an in-memory object into a format that can be stored on disk or transmitted across networks. <code>Deserialization</code> involves converting the stored representation back into an in-memory object with the exact same state it had when saved.</p>
<p><code>joblib</code> works by leveraging optimized binary file formats that compress and split objects, if necessary, to handle large datasets or complex models. When a model, such as a scikit-learn pipeline, is saved with <code>joblib</code>, it stores the entire model state including learned parameters and configurations. Later, when the model is reloaded, it will immediately be ready to make predictions as if it had just been trained.</p>
<p>By doing so, <code>joblib</code> helps streamline the deployment process. Instead of retraining the model every time the application restarts, developers and operations teams can load the saved model into memory and start making predictions. This reduces both computational overhead and startup latency.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> joblib

# Save the trained model to a <span class="hljs-keyword">file</span> <span class="hljs-keyword">for</span> future use
model_filename = <span class="hljs-string">'spam_detection_model.joblib'</span>
joblib.<span class="hljs-keyword">dump</span>(best_model, model_filename)

<span class="hljs-keyword">print</span>(f<span class="hljs-string">"Model saved to {model_filename}"</span>)
</code></pre>
<p>In this example, <code>best_model</code> likely refers to a finalized and tested pipeline or classifier. The file <code>spam_detection_model.joblib</code> will contain all the necessary information to predict new data. To reuse the model later, load it back into the environment:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-attr">loaded_model</span> = joblib.load(model_filename)
<span class="hljs-attr">predictions</span> = loaded_model.predict(new_messages)
</code></pre>
<p>This approach ensures that the entire workflow—training, evaluating, and deploying the model—remains efficient and easily reproducible.</p>
<hr>
<h2 id="model-evaluation-spam-detection-">Model Evaluation (Spam Detection)</h2>
<hr>
<p>To evaluate your model, upload it to the evaluation portal running on the Playground VM. If you are not currently using the Playground VM, you can initialize it at the bottom of the page.</p>
<p>If you have the Playground VM running, you can use this Python script to upload your model from Jupyter directly. Once evaluated, if your model meets the required performance criteria, you will receive a flag value. This flag can be used to answer the question or verify the model’s success.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-built_in">import</span> requests
<span class="hljs-built_in">import</span> json

<span class="hljs-comment"># Define the URL of the API endpoint</span>
<span class="hljs-attr">url</span> = <span class="hljs-string">"http://localhost:8000/api/upload"</span>

<span class="hljs-comment"># Path to the model file you want to upload</span>
<span class="hljs-attr">model_file_path</span> = <span class="hljs-string">"spam_detection_model.joblib"</span>

<span class="hljs-comment"># Open the file in binary mode and send the POST request</span>
<span class="hljs-keyword">with</span> open(model_file_path, <span class="hljs-string">"rb"</span>) as model_file:
    <span class="hljs-attr">files</span> = {<span class="hljs-string">"model"</span>: model_file}
    <span class="hljs-attr">response</span> = requests.post(url, <span class="hljs-attr">files=files)</span>

<span class="hljs-comment"># Pretty print the response from the server</span>
print(json.dumps(response.json(), <span class="hljs-attr">indent=4))</span>
</code></pre>
<p>If you are working from your own machine, ensure you have configured the HTB VPN to connect to the remote VM and spawned it. After connecting, access the model upload portal by navigating to <code>http://&lt;VM-IP&gt;:8000/</code> in your browser and then uploading your model.</p>
<hr>
<h2 id="network-anomaly-detection">Network Anomaly Detection</h2>
<hr>
<p><code>Anomaly detection</code> identifies data points that deviate significantly from the norm. In cybersecurity, such anomalies can indicate malicious activities, network intrusions, or other security breaches. <code>Random forests</code>, which are ensembles of <code>decision trees</code>, effectively handle complex, high-dimensional data and can be used to detect these anomalous patterns.</p>
<h3 id="random-forests">Random Forests</h3>
<p>A <code>Random Forest</code> is an ensemble machine-learning algorithm that builds multiple <code>decision trees</code> and aggregates their predictions. In classification tasks, each tree votes for a class, and the class receiving the majority votes is chosen. In regression tasks, the final prediction is the average of the individual tree outputs.</p>
<p>By combining the outputs of multiple trees, random forests often generalize better than a single decision tree, reducing <code>overfitting</code> and providing robust performance even in high-dimensional feature spaces.</p>
<p>Three key concepts shape the construction of a random forest:</p>
<ol>
<li><code>Bootstrapping</code>: Multiple subsets of the training data are created via sampling with replacement. Each subset trains a separate decision tree.</li>
<li><code>Tree Construction</code>: For each tree, a random subset of features is considered at every split, ensuring diversity and reducing correlations among trees.</li>
<li><code>Voting</code>: After all trees are trained, classification involves majority voting, while regression involves averaging predictions.</li>
</ol>
<h3 id="random-forests-for-anomaly-detection">Random Forests for Anomaly Detection</h3>
<p>When used for anomaly detection, a random forest is trained exclusively on data representing normal conditions. New, unseen data points are then evaluated against this learned normal behavior. Points that do not fit well, or that produce low confidence predictions, are flagged as potential anomalies.</p>
<p>This allows the model to detect unusual patterns, making it useful in scenarios such as identifying suspicious network traffic.</p>
<h3 id="nsl-kdd-dataset">NSL-KDD Dataset</h3>
<p>The <code>NSL-KDD</code> dataset refines the original <code>KDD Cup 1999</code> dataset by eliminating redundant entries and correcting imbalanced class distributions. Researchers commonly adopt it as a standard reference for measuring the performance of various intrusion detection models.</p>
<p><code>NSL-KDD</code> presents balanced, labeled instances of both normal and malicious network activities. This allows practitioners to perform not only binary classification (normal vs. abnormal) but also multi-class detection tasks targeting specific attack types. Such versatility makes <code>NSL-KDD</code> an invaluable resource for developing and testing intrusion detection techniques.</p>
<p>We&#39;ll be using a modified version of this dataset.</p>
<h3 id="downloading-the-dataset">Downloading the Dataset</h3>
<p>Before loading the NSL-KDD dataset, we must retrieve it from the provided URL. We can download the <code>.zip</code> file using Python&#39;s standard libraries and then extract it locally for further processing.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-built_in">import</span> requests, zipfile, io

<span class="hljs-comment"># URL for the NSL-KDD dataset</span>
<span class="hljs-attr">url</span> = <span class="hljs-string">"https://academy.hackthebox.com/storage/modules/292/KDD_dataset.zip"</span>

<span class="hljs-comment"># Download the zip file and extract its contents</span>
<span class="hljs-attr">response</span> = requests.get(url)
<span class="hljs-attr">z</span> = zipfile.ZipFile(io.BytesIO(response.content))
z.extractall('.')  <span class="hljs-comment"># Extracts to the current directory</span>
</code></pre>
<h3 id="loading-the-dataset">Loading the Dataset</h3>
<p>Properly loading the NSL-KDD dataset is essential before starting the preprocessing stage. This ensures that the data is consistently structured, with each column containing the correct information. Once loaded, the dataset can be inspected for quality, completeness, and potential preprocessing needs.</p>
<h4 id="importing-libraries">Importing Libraries</h4>
<p>We begin by importing all necessary libraries.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-title">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier
<span class="hljs-title">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-title">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
</code></pre>
<p>In this snippet:</p>
<ul>
<li><code>numpy</code> and <code>pandas</code> handle data loading and cleaning.</li>
<li><code>RandomForestClassifier</code> provides the algorithm we will use for anomaly detection.</li>
<li><code>train_test_split</code> and other metrics from <code>sklearn.metrics</code> support model evaluation and validation.</li>
<li><code>seaborn</code> and <code>matplotlib</code> assist in visualizing distributions, relationships, and model results.</li>
</ul>
<h4 id="defining-column-names-and-file-path">Defining Column Names and File Path</h4>
<p>The NSL-KDD dataset includes a set of predefined features and labels. We must map these features to meaningful column names to work with them directly. We define a list of column names corresponding to the various observed characteristics of network connections and attacks. Additionally, we set <code>file_path</code> to point to the dataset file, ensuring that <code>pandas</code> know where to read the data from.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Set the file path to the dataset</span>
file_path = <span class="hljs-string">r'KDD+.txt'</span>

<span class="hljs-comment"># Define the column names corresponding to the NSL-KDD dataset</span>
columns = [
    <span class="hljs-string">'duration'</span>, <span class="hljs-string">'protocol_type'</span>, <span class="hljs-string">'service'</span>, <span class="hljs-string">'flag'</span>, <span class="hljs-string">'src_bytes'</span>, <span class="hljs-string">'dst_bytes'</span>, 
    <span class="hljs-string">'land'</span>, <span class="hljs-string">'wrong_fragment'</span>, <span class="hljs-string">'urgent'</span>, <span class="hljs-string">'hot'</span>, <span class="hljs-string">'num_failed_logins'</span>, <span class="hljs-string">'logged_in'</span>, 
    <span class="hljs-string">'num_compromised'</span>, <span class="hljs-string">'root_shell'</span>, <span class="hljs-string">'su_attempted'</span>, <span class="hljs-string">'num_root'</span>, <span class="hljs-string">'num_file_creations'</span>, 
    <span class="hljs-string">'num_shells'</span>, <span class="hljs-string">'num_access_files'</span>, <span class="hljs-string">'num_outbound_cmds'</span>, <span class="hljs-string">'is_host_login'</span>, <span class="hljs-string">'is_guest_login'</span>, 
    <span class="hljs-string">'count'</span>, <span class="hljs-string">'srv_count'</span>, <span class="hljs-string">'serror_rate'</span>, <span class="hljs-string">'srv_serror_rate'</span>, <span class="hljs-string">'rerror_rate'</span>, <span class="hljs-string">'srv_rerror_rate'</span>, 
    <span class="hljs-string">'same_srv_rate'</span>, <span class="hljs-string">'diff_srv_rate'</span>, <span class="hljs-string">'srv_diff_host_rate'</span>, <span class="hljs-string">'dst_host_count'</span>, <span class="hljs-string">'dst_host_srv_count'</span>, 
    <span class="hljs-string">'dst_host_same_srv_rate'</span>, <span class="hljs-string">'dst_host_diff_srv_rate'</span>, <span class="hljs-string">'dst_host_same_src_port_rate'</span>, 
    <span class="hljs-string">'dst_host_srv_diff_host_rate'</span>, <span class="hljs-string">'dst_host_serror_rate'</span>, <span class="hljs-string">'dst_host_srv_serror_rate'</span>, 
    <span class="hljs-string">'dst_host_rerror_rate'</span>, <span class="hljs-string">'dst_host_srv_rerror_rate'</span>, <span class="hljs-string">'attack'</span>, <span class="hljs-string">'level'</span>
]
</code></pre>
<p>These column names ensure that each feature and label is properly identified. They include generic network statistics (e.g., <code>duration</code>, <code>src_bytes</code>, <code>dst_bytes</code>), categorical fields (<code>protocol_type</code>, <code>service</code>), and labels (<code>attack</code>, <code>level</code>), which classify the type of traffic observed.</p>
<h4 id="reading-the-dataset-into-a-dataframe">Reading the Dataset into a DataFrame</h4>
<p>With the file path and column names defined, we load the data into a <code>pandas</code> DataFrame. This provides a structured, tabular representation of the dataset, making it easier to inspect, preprocess, and visualize.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Read the combined NSL-KDD dataset into a DataFrame</span>
<span class="hljs-attr">df</span> = pd.read_csv(file_path, names=columns)
</code></pre>
<p>By executing this code, we now have a DataFrame <code>df</code> containing all the data from the NSL-KDD dataset with the appropriate column headers. The DataFrame is ready for further inspection, cleaning, and preprocessing steps. Before proceeding, we can briefly examine the dataset’s structure, check for missing values, and confirm that all features align with their intended data types.</p>
<p>Code: python</p>
<pre><code class="lang-python">print(<span class="hljs-name">df</span>.head())
</code></pre>
<hr>
<h2 id="preprocessing-and-splitting-the-dataset">Preprocessing and Splitting the Dataset</h2>
<hr>
<h3 id="preprocessing-the-dataset">Preprocessing the Dataset</h3>
<p>This section prepares the NSL-KDD dataset to train a random forest anomaly detection model. The primary goal is to transform the raw network traffic data into a usable format by creating classification targets, encoding categorical variables, and selecting important numeric features. We will produce both binary and multi-class targets, ensure that categorical data is machine-readable, and retain numeric metrics critical to the detection of abnormal traffic patterns.</p>
<h4 id="creating-a-binary-classification-target">Creating a Binary Classification Target</h4>
<p>The binary classification target identifies whether network traffic is normal or anomalous. We create a new column <code>attack_flag</code> in the DataFrame <code>df</code> to achieve this. Each row receives a label of <code>0</code> if the traffic is normal and <code>1</code> if it is an attack. This transformation simplifies the initial detection problem into a basic normal-versus-attack classification, which can be a starting point for a more granular analysis.</p>
<p>Code: python</p>
<pre><code class="lang-python"># Binary classification target
# Maps <span class="hljs-keyword">normal</span> traffic <span class="hljs-keyword">to</span> <span class="hljs-number">0</span> <span class="hljs-built_in">and</span> any <span class="hljs-built_in">type</span> of attack <span class="hljs-keyword">to</span> <span class="hljs-number">1</span>
df[<span class="hljs-string">'attack_flag'</span>] = df[<span class="hljs-string">'attack'</span>].apply(lambda <span class="hljs-variable">a:</span> <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">a</span> == <span class="hljs-string">'normal'</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>)
</code></pre>
<p>The value <code>normal</code> comes from the dataset; if we look at the dataset, you can see that all traffic is labeled <code>normal</code> or not:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-number">0</span>,tcp,ftp_data,SF,<span class="hljs-number">491</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">150</span>,<span class="hljs-number">25</span>,<span class="hljs-number">0.17</span>,<span class="hljs-number">0.03</span>,<span class="hljs-number">0.17</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.05</span>,<span class="hljs-number">0.0</span>,normal,<span class="hljs-number">20</span>
<span class="hljs-number">0</span>,tcp,private,S0,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">123</span>,<span class="hljs-number">6</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.05</span>,<span class="hljs-number">0.07</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">26</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">0.05</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,neptune,<span class="hljs-number">19</span>
</code></pre>
<h4 id="creating-the-multi-class-classification-target">Creating the Multi-Class Classification Target</h4>
<p>While a binary target is useful, it lacks granularity. To address this, we also create a multi-class classification target that distinguishes between different categories of attacks. We define lists categorizing specific attacks into four major groups:</p>
<ul>
<li><code>DoS</code> (Denial of Service) attacks such as <code>neptune</code> and <code>smurf</code></li>
<li><code>Probe</code> attacks that scan networks for vulnerabilities, like <code>satan</code> or <code>ipsweep</code></li>
<li><code>Privilege Escalation</code> attacks that attempt to gain unauthorized admin-level control, such as <code>buffer_overflow</code></li>
<li><code>Access</code> attacks that seek to breach system access controls, like <code>guess_passwd</code></li>
</ul>
<p>A custom function <code>map_attack</code> checks the type of attack and assigns it an integer:</p>
<ul>
<li><code>0</code> for normal traffic</li>
<li><code>1</code> for DoS attacks</li>
<li><code>2</code> for Probe attacks</li>
<li><code>3</code> for Privilege Escalation attacks</li>
<li><code>4</code> for Access attacks</li>
</ul>
<p>This expanded classification target allows models to learn to distinguish between normal and abnormal traffic and the nature of the observed attacks.</p>
<p>Code: python</p>
<pre><code class="lang-python"># Multi-<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">classification</span> <span class="hljs-title">target</span> <span class="hljs-title">categories</span></span>
dos_attacks = [<span class="hljs-string">'apache2'</span>, <span class="hljs-string">'back'</span>, <span class="hljs-string">'land'</span>, <span class="hljs-string">'neptune'</span>, <span class="hljs-string">'mailbomb'</span>, <span class="hljs-string">'pod'</span>, 
               <span class="hljs-string">'processtable'</span>, <span class="hljs-string">'smurf'</span>, <span class="hljs-string">'teardrop'</span>, <span class="hljs-string">'udpstorm'</span>, <span class="hljs-string">'worm'</span>]
probe_attacks = [<span class="hljs-string">'ipsweep'</span>, <span class="hljs-string">'mscan'</span>, <span class="hljs-string">'nmap'</span>, <span class="hljs-string">'portsweep'</span>, <span class="hljs-string">'saint'</span>, <span class="hljs-string">'satan'</span>]
privilege_attacks = [<span class="hljs-string">'buffer_overflow'</span>, <span class="hljs-string">'loadmdoule'</span>, <span class="hljs-string">'perl'</span>, <span class="hljs-string">'ps'</span>, 
                     <span class="hljs-string">'rootkit'</span>, <span class="hljs-string">'sqlattack'</span>, <span class="hljs-string">'xterm'</span>]
access_attacks = [<span class="hljs-string">'ftp_write'</span>, <span class="hljs-string">'guess_passwd'</span>, <span class="hljs-string">'http_tunnel'</span>, <span class="hljs-string">'imap'</span>, 
                  <span class="hljs-string">'multihop'</span>, <span class="hljs-string">'named'</span>, <span class="hljs-string">'phf'</span>, <span class="hljs-string">'sendmail'</span>, <span class="hljs-string">'snmpgetattack'</span>, 
                  <span class="hljs-string">'snmpguess'</span>, <span class="hljs-string">'spy'</span>, <span class="hljs-string">'warezclient'</span>, <span class="hljs-string">'warezmaster'</span>, 
                  <span class="hljs-string">'xclock'</span>, <span class="hljs-string">'xsnoop'</span>]

def map_attack(attack):
    <span class="hljs-keyword">if</span> attack <span class="hljs-keyword">in</span> dos_attacks:
        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>
    elif attack <span class="hljs-keyword">in</span> probe_attacks:
        <span class="hljs-keyword">return</span> <span class="hljs-number">2</span>
    elif attack <span class="hljs-keyword">in</span> privilege_attacks:
        <span class="hljs-keyword">return</span> <span class="hljs-number">3</span>
    elif attack <span class="hljs-keyword">in</span> access_attacks:
        <span class="hljs-keyword">return</span> <span class="hljs-number">4</span>
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>

# Assign multi-<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">category</span> <span class="hljs-title">to</span> <span class="hljs-title">each</span> <span class="hljs-title">row</span></span>
df[<span class="hljs-string">'attack_map'</span>] = df[<span class="hljs-string">'attack'</span>].apply(map_attack)
</code></pre>
<h4 id="encoding-categorical-variables">Encoding Categorical Variables</h4>
<p>Network traffic data often includes categorical attributes that are not directly usable by machine learning algorithms, which generally require numeric inputs. Two important features in the NSL-KDD dataset are <code>protocol_type</code> (e.g., <code>tcp</code>, <code>udp</code>) and <code>service</code> (e.g., <code>http</code>, <code>ftp</code>). These features categorize the nature of network interactions but must be transformed into numeric form.</p>
<p>We use one-hot encoding, provided by the <code>get_dummies</code> function in pandas. This approach creates a binary indicator variable for each category, ensuring that no ordinal relationship is implied between different protocols or services. After encoding, each categorical value is represented by a separate column indicating its presence (<code>1</code>) or absence (<code>0</code>).</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Encoding categorical variables</span>
<span class="hljs-attr">features_to_encode</span> = [<span class="hljs-string">'protocol_type'</span>, <span class="hljs-string">'service'</span>]
<span class="hljs-attr">encoded</span> = pd.get_dummies(df[features_to_encode])
</code></pre>
<h4 id="selecting-numeric-features">Selecting Numeric Features</h4>
<p>Beyond categorical variables, the dataset contains a range of numeric features that describe various aspects of network traffic. These include basic metrics like <code>duration</code>, <code>src_bytes</code>, and <code>dst_bytes</code>, as well as more specialized features such as <code>serror_rate</code> and <code>dst_host_srv_diff_host_rate</code>, which capture statistical properties of the network sessions. By selecting these numeric features, we ensure the model has access to both raw volume data and more nuanced, derived statistics that help distinguish normal from abnormal patterns.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Numeric features that capture various statistical properties of the traffic</span>
<span class="hljs-attribute">numeric_features</span> = [
    <span class="hljs-string">'duration'</span>, <span class="hljs-string">'src_bytes'</span>, <span class="hljs-string">'dst_bytes'</span>, <span class="hljs-string">'wrong_fragment'</span>, <span class="hljs-string">'urgent'</span>, <span class="hljs-string">'hot'</span>, 
    <span class="hljs-string">'num_failed_logins'</span>, <span class="hljs-string">'num_compromised'</span>, <span class="hljs-string">'root_shell'</span>, <span class="hljs-string">'su_attempted'</span>, 
    <span class="hljs-string">'num_root'</span>, <span class="hljs-string">'num_file_creations'</span>, <span class="hljs-string">'num_shells'</span>, <span class="hljs-string">'num_access_files'</span>, 
    <span class="hljs-string">'num_outbound_cmds'</span>, <span class="hljs-string">'count'</span>, <span class="hljs-string">'srv_count'</span>, <span class="hljs-string">'serror_rate'</span>, 
    <span class="hljs-string">'srv_serror_rate'</span>, <span class="hljs-string">'rerror_rate'</span>, <span class="hljs-string">'srv_rerror_rate'</span>, <span class="hljs-string">'same_srv_rate'</span>, 
    <span class="hljs-string">'diff_srv_rate'</span>, <span class="hljs-string">'srv_diff_host_rate'</span>, <span class="hljs-string">'dst_host_count'</span>, <span class="hljs-string">'dst_host_srv_count'</span>, 
    <span class="hljs-string">'dst_host_same_srv_rate'</span>, <span class="hljs-string">'dst_host_diff_srv_rate'</span>, 
    <span class="hljs-string">'dst_host_same_src_port_rate'</span>, <span class="hljs-string">'dst_host_srv_diff_host_rate'</span>, 
    <span class="hljs-string">'dst_host_serror_rate'</span>, <span class="hljs-string">'dst_host_srv_serror_rate'</span>, <span class="hljs-string">'dst_host_rerror_rate'</span>, 
    <span class="hljs-string">'dst_host_srv_rerror_rate'</span>
]
</code></pre>
<h4 id="preparing-the-dataset">Preparing the Dataset</h4>
<p>The final step is to combine the one-hot encoded categorical features with the selected numeric features. We join them into a single DataFrame <code>train_set</code> that will serve as the primary input to our machine-learning model. We also store the multi-class target variable <code>attack_map</code> as <code>multi_y</code> for classification tasks. At this stage, the data is in a suitable format for splitting into training, validation, test sets, and subsequently training the random forest anomaly detection model.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Combine encoded categorical variables and numeric features</span>
<span class="hljs-attr">train_set</span> = encoded.join(df[numeric_features])

<span class="hljs-comment"># Multi-class target variable</span>
<span class="hljs-attr">multi_y</span> = df[<span class="hljs-string">'attack_map'</span>]
</code></pre>
<h3 id="splitting-the-dataset">Splitting the Dataset</h3>
<p>In the <code>Data Transformation</code> section, we discussed the rationale and methods for splitting data into training, validation, and test sets. We now apply those principles specifically to the NSL-KDD dataset, ensuring that our random forest anomaly detection model is trained, tuned, and evaluated on distinct subsets.</p>
<h4 id="splitting-data-into-training-and-test-sets">Splitting Data into Training and Test Sets</h4>
<p>We use <code>train_test_split</code> to allocate a portion of the data for testing, ensuring that our final evaluations occur on unseen data.</p>
<p>Code: python</p>
<pre><code class="lang-python"># Split <span class="hljs-meta">data</span> into training <span class="hljs-keyword">and </span>test <span class="hljs-meta">sets</span> for <span class="hljs-keyword">multi-class </span>classification
<span class="hljs-symbol">train_X</span>, test_X, train_y, test_y = train_test_split(train_set, <span class="hljs-keyword">multi_y, </span>test_size<span class="hljs-number">=0</span>.<span class="hljs-number">2</span>, random_state<span class="hljs-number">=1337</span>)
</code></pre>
<h4 id="creating-a-validation-set-from-the-training-data">Creating a Validation Set from the Training Data</h4>
<p>We further split the training data to create a validation set. This supports model tuning and hyperparameter optimization without contaminating the final test data.</p>
<p>Code: python</p>
<pre><code class="lang-python"># Further split the training set into separate training <span class="hljs-keyword">and </span>validation <span class="hljs-meta">sets</span>
<span class="hljs-keyword">multi_train_X, </span><span class="hljs-keyword">multi_val_X, </span><span class="hljs-keyword">multi_train_y, </span><span class="hljs-keyword">multi_val_y </span>= train_test_split(train_X, train_y, test_size<span class="hljs-number">=0</span>.<span class="hljs-number">3</span>, random_state<span class="hljs-number">=1337</span>)
</code></pre>
<h4 id="final-split-variables">Final Split Variables</h4>
<p>After splitting, we have:</p>
<ul>
<li><code>train_X</code>, <code>train_y</code>: Core training set</li>
<li><code>test_X</code>, <code>test_y</code>: Reserved for the final performance evaluation</li>
<li><code>multi_train_X</code>, <code>multi_train_y</code>: Training subset for fitting the model</li>
<li><code>multi_val_X</code>, <code>multi_val_y</code>: Validation subset for hyperparameter tuning</li>
</ul>
<p>This careful partitioning, applied after the transformations and encodings discussed earlier, ensures that the model development process remains consistent and that the final evaluation is unbiased and reflective of real-world performance.</p>
<hr>
<h2 id="training-and-evaluation-network-anomaly-detection-">Training and Evaluation (Network Anomaly Detection)</h2>
<hr>
<p>In this section, we will train a random forest model on the NSL-KDD dataset for multi-class classification. The goal is to build a model that can accurately classify network traffic into different attack categories or as normal traffic.</p>
<h3 id="training-the-model">Training the Model</h3>
<p>Code: python</p>
<pre><code class="lang-python"># Train RandomForest model <span class="hljs-keyword">for</span> multi-<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">classification</span></span>
rf_model_multi = RandomForestClassifier(random_state=<span class="hljs-number">1337</span>)
rf_model_multi.fit(multi_train_X, multi_train_y)
</code></pre>
<p>The first step in this process is to train the random forest model using the training subset of the dataset. We initialize a <code>RandomForestClassifier</code> with the <code>random_state</code> parameter set to <code>1337</code> to ensure reproducibility. The <code>fit</code> method is then used to train the model on the features <code>multi_train_X</code> and the target variable <code>multi_train_y</code>. This step builds the model by learning patterns from the training data.</p>
<h3 id="evaluating-the-model-on-the-validation-set">Evaluating the Model on the Validation Set</h3>
<p>Next, we will evaluate the performance of the trained random forest model on the validation set. The goal is to assess the model&#39;s accuracy and other performance metrics to ensure it generalizes well to unseen data.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># Predict and evaluate the model on the validation set</span>
multi_predictions = rf_model_multi.predict(multi_val_X)
accuracy = accuracy_score(multi_val_y, multi_predictions)
precision = precision_score(multi_val_y, multi_predictions, average=<span class="hljs-string">'weighted'</span>)
recall = recall_score(multi_val_y, multi_predictions, average=<span class="hljs-string">'weighted'</span>)
f1 = f1_score(multi_val_y, multi_predictions, average=<span class="hljs-string">'weighted'</span>)
<span class="hljs-literal">print</span>(f<span class="hljs-string">"Validation Set Evaluation:"</span>)
<span class="hljs-literal">print</span>(f<span class="hljs-string">"Accuracy: {accuracy:.4f}"</span>)
<span class="hljs-literal">print</span>(f<span class="hljs-string">"Precision: {precision:.4f}"</span>)
<span class="hljs-literal">print</span>(f<span class="hljs-string">"Recall: {recall:.4f}"</span>)
<span class="hljs-literal">print</span>(f<span class="hljs-string">"F1-Score: {f1:.4f}"</span>)

<span class="hljs-comment"># Confusion Matrix for Validation Set</span>
conf_matrix = confusion_matrix(multi_val_y, multi_predictions)
class_labels = [<span class="hljs-string">'Normal'</span>, <span class="hljs-string">'DoS'</span>, <span class="hljs-string">'Probe'</span>, <span class="hljs-string">'Privilege'</span>, <span class="hljs-string">'Access'</span>]
sns.heatmap(conf_matrix, annot=True, fmt=<span class="hljs-string">'d'</span>, cmap=<span class="hljs-string">'Blues'</span>,
            xticklabels=class_labels,
            yticklabels=class_labels)
plt.title(<span class="hljs-string">'Network Anomaly Detection - Validation Set'</span>)
plt.xlabel(<span class="hljs-string">'Predicted'</span>)
plt.ylabel(<span class="hljs-string">'Actual'</span>)
plt.<span class="hljs-literal">show</span>()

<span class="hljs-comment"># Classification Report for Validation Set</span>
<span class="hljs-literal">print</span>(<span class="hljs-string">"Classification Report for Validation Set:"</span>)
<span class="hljs-literal">print</span>(classification_report(multi_val_y, multi_predictions, target_names=class_labels))
</code></pre>
<p>After training the model, we use it to make predictions on the validation set. The <code>predict</code> method of the <code>RandomForestClassifier</code> is used to generate predictions for the features <code>multi_val_X</code>. We then calculate various performance metrics using functions from <code>sklearn.metrics</code>:</p>
<ul>
<li><code>Accuracy</code>: The proportion of correctly classified instances.</li>
<li><code>Precision</code>: The ratio of true positive predictions to the total predicted positives.</li>
<li><code>Recall</code>: The ratio of true positive predictions to the total actual positives.</li>
<li><code>F1-Score</code>: The harmonic mean of precision and recall.</li>
</ul>
<p>These metrics are printed to evaluate the model&#39;s performance on the validation set comprehensively.</p>
<p>We also generate a confusion matrix using <code>confusion_matrix</code> and visualize it using <code>seaborn</code> and <code>matplotlib</code>. The confusion matrix provides a detailed breakdown of the model&#39;s predictions, showing each class&#39;s number of true positives, true negatives, false positives, and false negatives.</p>
<p>Finally, we print a classification report that includes precision, recall, F1-score, and support for each class. This report gives a more granular view of the model&#39;s performance across different classes.</p>
<h3 id="testing-the-model-on-the-test-set">Testing the Model on the Test Set</h3>
<p><img src="https://academy.hackthebox.com/storage/modules/292/anomaly_test.png" alt="Confusion matrix for network anomaly detection: 15,349 normal, 10,708 DoS, 2,788 probe, 703 access, with minor misclassifications."></p>
<p>Next, we will evaluate the final performance of the trained random forest model on the test set. The goal is to assess the model&#39;s ability to generalize to completely unseen data and provide a final evaluation of its performance.</p>
<p>Code: python</p>
<pre><code class="lang-python"># Final evaluation on the test <span class="hljs-keyword">set</span>
test_multi_predictions = rf_model_multi.predict(test_X)
test_accuracy = accuracy_score(test_y, test_multi_predictions)
test_precision = precision_score(test_y, test_multi_predictions, average=<span class="hljs-string">'weighted'</span>)
test_recall = recall_score(test_y, test_multi_predictions, average=<span class="hljs-string">'weighted'</span>)
test_f1 = f1_score(test_y, test_multi_predictions, average=<span class="hljs-string">'weighted'</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"\nTest Set Evaluation:"</span>)
<span class="hljs-built_in">print</span>(f<span class="hljs-string">"Accuracy: {test_accuracy:.4f}"</span>)
<span class="hljs-built_in">print</span>(f<span class="hljs-string">"Precision: {test_precision:.4f}"</span>)
<span class="hljs-built_in">print</span>(f<span class="hljs-string">"Recall: {test_recall:.4f}"</span>)
<span class="hljs-built_in">print</span>(f<span class="hljs-string">"F1-Score: {test_f1:.4f}"</span>)

# Confusion Matrix <span class="hljs-keyword">for</span> Test <span class="hljs-built_in">Set</span>
test_conf_matrix = confusion_matrix(test_y, test_multi_predictions)
sns.heatmap(test_conf_matrix, annot=True, fmt=<span class="hljs-string">'d'</span>, cmap=<span class="hljs-string">'Blues'</span>,
            xticklabels=class_labels,
            yticklabels=class_labels)
plt.title(<span class="hljs-string">'Network Anomaly Detection'</span>)
plt.xlabel(<span class="hljs-string">'Predicted'</span>)
plt.ylabel(<span class="hljs-string">'Actual'</span>)
plt.show()

# Classification Report <span class="hljs-keyword">for</span> Test <span class="hljs-built_in">Set</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Classification Report for Test Set:"</span>)
<span class="hljs-built_in">print</span>(classification_report(test_y, test_multi_predictions, target_names=class_labels))
</code></pre>
<p>The final step in our process is to evaluate the model on the test set. We use the <code>predict</code> method to generate predictions for the features <code>test_X</code>. Similar to the validation set evaluation, we calculate and print various performance metrics:</p>
<ul>
<li><code>Accuracy</code>: The proportion of correctly classified instances.</li>
<li><code>Precision</code>: The ratio of true positive predictions to the total predicted positives.</li>
<li><code>Recall</code>: The ratio of true positive predictions to the total actual positives.</li>
<li><code>F1-Score</code>: The harmonic mean of precision and recall.</li>
</ul>
<p>We also generate a confusion matrix for the test set and visualize it using <code>seaborn</code> and <code>matplotlib</code>. This matrix provides a detailed breakdown of the model&#39;s predictions on the test data, showing each class&#39;s number of true positives, true negatives, false positives, and false negatives.</p>
<p>Finally, we print a classification report that includes precision, recall, F1-score, and support for each class. This report gives a comprehensive view of the model&#39;s performance across different classes on the test set.</p>
<p>By executing this code, we have trained a random forest model, evaluated its performance on both the validation and test sets, and generated detailed reports and visualizations to assess its effectiveness in classifying network traffic.</p>
<h3 id="saving-model">Saving Model</h3>
<p>Save your model using this code:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> joblib

<span class="hljs-comment"># Save the trained model to a file</span>
model_filename = <span class="hljs-string">'network_anomaly_detection_model.joblib'</span>
joblib.dump(rf_model_multi, model_filename)

<span class="hljs-built_in">print</span>(f<span class="hljs-string">"Model saved to {model_filename}"</span>)
</code></pre>
<hr>
<h2 id="model-evaluation-network-anomaly-detection-">Model Evaluation (Network Anomaly Detection)</h2>
<hr>
<p>To evaluate your model, upload it to the evaluation portal running on the Playground VM. If you are not currently using the Playground VM, you can initialize it at the bottom of the page.</p>
<p>If you have the Playground VM running, you can use this Python script to upload your model from Jupyter directly. Once evaluated, if your model meets the required performance criteria, you will receive a flag value. This flag can be used to answer the question or verify the model’s success.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-built_in">import</span> requests
<span class="hljs-built_in">import</span> json

<span class="hljs-comment"># Define the URL of the API endpoint</span>
<span class="hljs-attr">url</span> = <span class="hljs-string">"http://localhost:8001/api/upload"</span>

<span class="hljs-comment"># Path to the model file you want to upload</span>
<span class="hljs-attr">model_file_path</span> = <span class="hljs-string">"network_anomaly_detection_model.joblib"</span>

<span class="hljs-comment"># Open the file in binary mode and send the POST request</span>
<span class="hljs-keyword">with</span> open(model_file_path, <span class="hljs-string">"rb"</span>) as model_file:
    <span class="hljs-attr">files</span> = {<span class="hljs-string">"model"</span>: model_file}
    <span class="hljs-attr">response</span> = requests.post(url, <span class="hljs-attr">files=files)</span>

<span class="hljs-comment"># Pretty print the response from the server</span>
print(json.dumps(response.json(), <span class="hljs-attr">indent=4))</span>
</code></pre>
<p>If you are working from your own machine, ensure you have configured the HTB VPN to connect to the remote VM and spawned it. After connecting, access the model upload portal by navigating to <code>http://&lt;VM-IP&gt;:8001/</code> in your browser and then uploading your model.</p>
<hr>
<h2 id="malware-classification">Malware Classification</h2>
<hr>
<p>Malware is software designed to cause damage or unauthorized actions on a computer system or network. Malware can be categorized based on its characteristics, mode of operation, and purpose, among other factors. A malware category is commonly referred to as a <code>malware family</code>. We can look at <a href="https://malpedia.caad.fkie.fraunhofer.de/families">malpedia</a> to explore details about different malware families. Famous examples include <a href="https://malpedia.caad.fkie.fraunhofer.de/details/win.emotet">Emotet</a> and <a href="https://malpedia.caad.fkie.fraunhofer.de/details/win.wannacryptor">WannaCry</a>.</p>
<p>Features of malware to consider for classification include its behavior or functionality, delivery and propagation methods, and technical traits. As such, manual malware classification requires a combination of static and dynamic analysis, including time-consuming reverse engineering of the malware binary. Thus, using ML classifiers to aid in malware classification can significantly speed up the process.</p>
<p>In this section, we will implement a malware classifier based on the technique explored in <a href="https://arxiv.org/pdf/2010.16108">this</a> paper, which explores malware classification based on malware images.</p>
<hr>
<h3 id="malware-image-classification">Malware Image Classification</h3>
<p>While classifying malware based on images might initially sound counterintuitive, we will explore the dataset in the upcoming section and learn why this approach makes sense. For this module, training a classifier on images has the obvious advantage that we do not have to handle potentially dangerous malicious binaries directly. By only handling images that represent these binaries, we cannot accidentally infect our system with malware. Therefore, it is more appropriate for a learning environment than dealing with the binary files directly.</p>
<p>In the upcoming sections, we will explore the process of training a CNN to classify the malware images.</p>
<hr>
<h2 id="the-malware-dataset">The Malware Dataset</h2>
<hr>
<p>The dataset of malware images we will be using is the <code>malimg</code> dataset, which we can obtain <a href="https://drive.google.com/file/d/1M83VzyIQj_kuE9XzhClGK5TZWh1T_pr-/view">here</a> or <a href="https://www.kaggle.com/api/v1/datasets/download/ikrambenabd/malimg-original">here</a>. It was proposed in <a href="https://dl.acm.org/doi/10.1145/2016904.2016908">this</a> paper.</p>
<hr>
<h3 id="malimg-dataset">Malimg Dataset</h3>
<p>We can download and unpack the dataset using the following commands:</p>
<p>&#x20; The Malware Dataset</p>
<pre><code class="lang-shell-session">root<span class="hljs-meta">@htb</span>[<span class="hljs-regexp">/htb]$ wget https:/</span><span class="hljs-regexp">/www.kaggle.com/</span>api<span class="hljs-regexp">/v1/</span>datasets<span class="hljs-regexp">/download/</span>ikrambenabd/malimg-original -O malimg.zip

root<span class="hljs-meta">@htb</span>[/htb]$ unzip malimg.zip
</code></pre>
<p>The dataset consists of 9339 image files for 25 different malware families. The dataset is organized in folders, where each folder contains all samples for a single malware family. The folder name corresponds to the malware family&#39;s name:</p>
<p>&#x20; The Malware Dataset</p>
<pre><code class="lang-shell-session">root@htb[/htb]$ ls malimg_paper_dataset_imgs

 Adialer<span class="hljs-selector-class">.C</span>        C2LOP<span class="hljs-selector-class">.P</span>          Lolyda<span class="hljs-selector-class">.AA3</span>      <span class="hljs-string">'Swizzor.gen!I'</span>
 Agent<span class="hljs-selector-class">.FYI</span>        Dialplatform<span class="hljs-selector-class">.B</span>   Lolyda<span class="hljs-selector-class">.AT</span>        VB<span class="hljs-selector-class">.AT</span>
 Allaple<span class="hljs-selector-class">.A</span>        Dontovo<span class="hljs-selector-class">.A</span>       <span class="hljs-string">'Malex.gen!J'</span>     Wintrim<span class="hljs-selector-class">.BX</span>
 Allaple<span class="hljs-selector-class">.L</span>        Fakerean         Obfuscator<span class="hljs-selector-class">.AD</span>    Yuner<span class="hljs-selector-class">.A</span>
<span class="hljs-string">'Alueron.gen!J'</span>   Instantaccess   <span class="hljs-string">'Rbot!gen'</span>
 Autorun<span class="hljs-selector-class">.K</span>        Lolyda<span class="hljs-selector-class">.AA1</span>       Skintrim<span class="hljs-selector-class">.N</span>
<span class="hljs-string">'C2LOP.gen!g'</span>     Lolyda<span class="hljs-selector-class">.AA2</span>      <span class="hljs-string">'Swizzor.gen!E'</span>
</code></pre>
<p>Each image contains a visual representation of a PE file, which is a Windows executable. The images are grayscale in <code>png</code> format:</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/dataset_1.png" alt="Image of static noise pattern."></p>
<p>These images are a direct representation of the malware binaries. Each pixel in the image represents a single byte in the binary. The byte can be any value in the 0-255 range. The exact value is represented in the corresponding pixel&#39;s brightness. A byte with the value <code>0</code> results in a black pixel, a value of <code>255</code> results in a white pixel, and a value in between results in the corresponding gray pixel.</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/malware_diagram.png" alt="Diagram showing malware binary conversion to an 8-bit vector, then to a grayscale image."></p>
<p>Each binary byte is fully encoded within the image, meaning the image can be used to exactly reconstruct the binary without any loss of information. Furthermore, the images can visibly convey patterns in the binary. For instance, consider the following two image samples from the <code>FakeRean</code> malware family. We can see distinct patterns in both malware images.</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/dataset_2.png" alt="Image of static noise pattern."></p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/dataset_3.png" alt="Image of static noise pattern."></p>
<hr>
<h3 id="exploring-the-dataset">Exploring the Dataset</h3>
<p>To familiarize ourselves with the dataset, let&#39;s start exploring it by creating a plot of the class distribution within it. This enables us to spot classes that are over- or underrepresented.</p>
<p>To achieve this, we will need the following imports as well as a base path to the folder containing the data:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns

<span class="hljs-type">DATA_BASE_PATH</span> = <span class="hljs-string">"./malimg_paper_dataset_imgs/"</span>
</code></pre>
<p>Afterward, we can iterate over all malware families and count the number of images within the corresponding folder to compute the overall class distribution:</p>
<p>Code: python</p>
<pre><code class="lang-python"># compute the <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">distribution</span></span>
dist = {}
<span class="hljs-keyword">for</span> mlw_class <span class="hljs-keyword">in</span> <span class="hljs-built_in">os</span>.listdir(DATA_BASE_PATH):
    mlw_dir = <span class="hljs-built_in">os</span>.path.join(DATA_BASE_PATH, mlw_class)
    dist[mlw_class] = len(<span class="hljs-built_in">os</span>.listdir(mlw_dir))
</code></pre>
<p>Finally, we can create a barplot to visualize the class distribution:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># plot the class distribution</span>

<span class="hljs-comment"># HTB Color Palette</span>
<span class="hljs-attr">htb_green</span> = <span class="hljs-string">"#9FEF00"</span>
<span class="hljs-attr">node_black</span> = <span class="hljs-string">"#141D2B"</span>
<span class="hljs-attr">hacker_grey</span> = <span class="hljs-string">"#A4B1CD"</span>

<span class="hljs-comment"># data</span>
<span class="hljs-attr">classes</span> = list(dist.keys())
<span class="hljs-attr">frequencies</span> = list(dist.values())

<span class="hljs-comment"># plot</span>
plt.figure(<span class="hljs-attr">facecolor=node_black)</span>
sns.barplot(<span class="hljs-attr">y=classes,</span> <span class="hljs-attr">x=frequencies,</span> <span class="hljs-attr">edgecolor</span> = <span class="hljs-string">"black"</span>, <span class="hljs-attr">orient='h',</span> <span class="hljs-attr">color=htb_green)</span>
plt.title(<span class="hljs-string">"Malware Class Distribution"</span>, <span class="hljs-attr">color=htb_green)</span>
plt.xlabel(<span class="hljs-string">"Malware Class Frequency"</span>, <span class="hljs-attr">color=htb_green)</span>
plt.ylabel(<span class="hljs-string">"Malware Class"</span>, <span class="hljs-attr">color=htb_green)</span>
plt.xticks(<span class="hljs-attr">color=hacker_grey)</span>
plt.yticks(<span class="hljs-attr">color=hacker_grey)</span>
<span class="hljs-attr">ax</span> = plt.gca()
ax.set_facecolor(node_black)
ax.spines['bottom'].set_color(hacker_grey)
ax.spines['top'].set_color(node_black)
ax.spines['right'].set_color(node_black)
ax.spines['left'].set_color(hacker_grey)
plt.show()
</code></pre>
<p>From the resulting diagram, we can identify which malware families are represented more than others, potentially skewing the model. Suppose the trained model does not provide the expected performance in accuracy, number of false positives, and number of false negatives. In that case, we may want to fine-tune the dataset before training to ensure a more balanced class distribution.</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/dataset_4_fixed.png" alt="Bar chart showing malware class distribution, with Allaple.A and Allaple.L having the highest frequencies."></p>
<hr>
<h2 id="preprocessing-the-malware-dataset">Preprocessing the Malware Dataset</h2>
<hr>
<p>We need to prepare the data before we can feed the images to a CNN for training and inference. In particular, we need to split the data into two distinct datasets: a training and a test set. Furthermore, we need to apply the preprocessing functions expected by our model so the model can work on the images. Lastly, we must create <code>DataLoaders</code> that we can use during training and inference.</p>
<hr>
<h3 id="preparing-the-datasets">Preparing the Datasets</h3>
<p>To split the data into two distinct datasets, one for training and one for testing, we will use the library <a href="https://pypi.org/project/split-folders/">split-folders</a>, which we can install with <code>pip</code>:</p>
<p>&#x20; Preprocessing the Malware Dataset</p>
<pre><code class="lang-shell-session"><span class="hljs-selector-tag">root</span>@<span class="hljs-keyword">htb</span>[/<span class="hljs-keyword">htb</span>]$ pip3 install split-folders
</code></pre>
<p>Afterward, we can use the following code to split the data accordingly. We will use an <code>80-20</code> split, meaning 80% of the data will be used for training and 20% for testing:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-built_in">import</span> splitfolders

<span class="hljs-attr">DATA_BASE_PATH</span> = <span class="hljs-string">"./malimg_paper_dataset_imgs/"</span>
<span class="hljs-attr">TARGET_BASE_PATH</span> = <span class="hljs-string">"./newdata/"</span>

<span class="hljs-attr">TRAINING_RATIO</span> = <span class="hljs-number">0.8</span>
<span class="hljs-attr">TEST_RATIO</span> = <span class="hljs-number">1</span> - TRAINING_RATIO

splitfolders.ratio(<span class="hljs-attr">input=DATA_BASE_PATH,</span> <span class="hljs-attr">output=TARGET_BASE_PATH,</span> <span class="hljs-attr">ratio=(TRAINING_RATIO,</span> <span class="hljs-number">0</span>, TEST_RATIO))
</code></pre>
<p>After running the code once, a new directory <code>./newdata/</code> will be created containing three folders:</p>
<p>&#x20; Preprocessing the Malware Dataset</p>
<pre><code class="lang-shell-session">root@htb[/htb]$ ls -la ./newdata/

total <span class="hljs-number">0</span>
drwxr-xr-x <span class="hljs-number">1</span> <span class="hljs-built_in">t</span> <span class="hljs-built_in">t</span>  <span class="hljs-number">24</span> <span class="hljs-number">26</span>. Nov <span class="hljs-symbol">10:52</span> .
drwxr-xr-x <span class="hljs-number">1</span> <span class="hljs-built_in">t</span> <span class="hljs-built_in">t</span> <span class="hljs-number">160</span> <span class="hljs-number">26</span>. Nov <span class="hljs-symbol">10:52</span> ..
drwxr-xr-x <span class="hljs-number">1</span> <span class="hljs-built_in">t</span> <span class="hljs-built_in">t</span> <span class="hljs-number">498</span> <span class="hljs-number">26</span>. Nov <span class="hljs-symbol">10:52</span> test
drwxr-xr-x <span class="hljs-number">1</span> <span class="hljs-built_in">t</span> <span class="hljs-built_in">t</span> <span class="hljs-number">498</span> <span class="hljs-number">26</span>. Nov <span class="hljs-symbol">10:52</span> train
drwxr-xr-x <span class="hljs-number">1</span> <span class="hljs-built_in">t</span> <span class="hljs-built_in">t</span> <span class="hljs-number">498</span> <span class="hljs-number">26</span>. Nov <span class="hljs-symbol">10:52</span> val
</code></pre>
<p>The <code>test</code> folder contains the test dataset, the <code>train</code> folder contains the training dataset, and the <code>val</code> folder contains the validation dataset. In this case, we will not use a validation data set, which is why the validation data set is empty. We can confirm the 80-20 split by counting the number of files in each dataset:</p>
<p>&#x20; Preprocessing the Malware Dataset</p>
<pre><code class="lang-shell-session">root@htb[<span class="hljs-regexp">/htb]$ find ./newdata</span><span class="hljs-regexp">/test/</span> -<span class="hljs-keyword">type</span> f | wc -l

<span class="hljs-number">1880</span>
</code></pre>
<p>&#x20; Preprocessing the Malware Dataset</p>
<pre><code class="lang-shell-session">root@htb[<span class="hljs-regexp">/htb]$ find ./newdata</span><span class="hljs-regexp">/train/</span> -<span class="hljs-keyword">type</span> f | wc -l

<span class="hljs-number">7459</span>
</code></pre>
<p>&#x20; Preprocessing the Malware Dataset</p>
<pre><code class="lang-shell-session">root<span class="hljs-meta">@htb</span>[/htb]$ find ./newdata/<span class="hljs-keyword">val</span>/ -<span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">f</span> <span class="hljs-title">|</span> <span class="hljs-title">wc</span> <span class="hljs-title">-l</span></span>

<span class="hljs-number">0</span>
</code></pre>
<p>The split was successful, as we can see. We can now create <code>DataLoaders</code> for training and inference and apply the required preprocessing to the images.</p>
<hr>
<h3 id="applying-preprocessing-creating-dataloaders">Applying Preprocessing &amp; Creating DataLoaders</h3>
<p>In the first step, let us define the preprocessing required for our model to read the data. For CNNs, this typically requires a resizing such that all input images are the same size and a normalization. Normalization ensures that the data is standardized before the data is fed to the model. This results in a model that is easier to train. In PyTorch, our preprocessing looks like this:</p>
<p>Code: python</p>
<pre><code class="lang-python">from torchvision import transforms

# Define preprocessing transforms
transform = transforms.Compose([
    transforms.Resize((<span class="hljs-number">75</span>, <span class="hljs-number">75</span>)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], std=[<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])
])
</code></pre>
<p>Afterward, we can load the datasets from their corresponding folders and apply the preprocessing functions. We need to specify the root folder for each dataset in the <code>root</code> parameter and the preprocessing transform in the <code>transform</code> parameter. As we have discussed above, the root folders for the datasets are <code>./newdata/train/</code> and <code>./newdata/test/</code>, respectively.</p>
<p>Code: python</p>
<pre><code class="lang-python">from torchvision.datasets <span class="hljs-built_in">import</span> ImageFolder
<span class="hljs-built_in">import</span> os

<span class="hljs-attr">BASE_PATH</span> = <span class="hljs-string">"./newdata/"</span>

<span class="hljs-comment"># Load training and test datasets</span>
<span class="hljs-attr">train_dataset</span> = ImageFolder(
    <span class="hljs-attr">root=os.path.join(BASE_PATH,</span> <span class="hljs-string">"train"</span>),
    <span class="hljs-attr">transform=transform</span>
)

<span class="hljs-attr">test_dataset</span> = ImageFolder(
    <span class="hljs-attr">root=os.path.join(BASE_PATH,</span> <span class="hljs-string">"test"</span>),
    <span class="hljs-attr">transform=transform</span>
)
</code></pre>
<p>Finally, we can create <code>DataLoader</code> instances, which we can use to iterate over the data for training and inference. We can supply a batch size and specify the number of workers to load the data in the <code>num_workers</code> parameter. This enables parallelization and will speed up the data handling:</p>
<p>Code: python</p>
<pre><code class="lang-python">from torch.utils.data <span class="hljs-built_in">import</span> DataLoader

<span class="hljs-attr">TRAIN_BATCH_SIZE</span> = <span class="hljs-number">1024</span>
<span class="hljs-attr">TEST_BATCH_SIZE</span> = <span class="hljs-number">1024</span>

<span class="hljs-comment"># Create data loaders</span>
<span class="hljs-attr">train_loader</span> = DataLoader(
    train_dataset,
    <span class="hljs-attr">batch_size=TRAIN_BATCH_SIZE,</span>
    <span class="hljs-attr">shuffle=True,</span>
    <span class="hljs-attr">num_workers=2</span>
)

<span class="hljs-attr">test_loader</span> = DataLoader(
    test_dataset,
    <span class="hljs-attr">batch_size=TEST_BATCH_SIZE,</span>
    <span class="hljs-attr">shuffle=False,</span>
    <span class="hljs-attr">num_workers=2</span>
)
</code></pre>
<p>Let us take a look at one of the preprocessed images to see its effects:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-built_in">import</span> matplotlib.pyplot as plt

<span class="hljs-comment"># HTB Color Palette</span>
<span class="hljs-attr">htb_green</span> = <span class="hljs-string">"#9FEF00"</span>
<span class="hljs-attr">node_black</span> = <span class="hljs-string">"#141D2B"</span>
<span class="hljs-attr">hacker_grey</span> = <span class="hljs-string">"#A4B1CD"</span>

<span class="hljs-comment"># image</span>
<span class="hljs-attr">sample</span> = next(iter(train_loader))[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]

<span class="hljs-comment"># plot</span>
plt.figure(<span class="hljs-attr">facecolor=node_black)</span>
plt.imshow(sample.permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>))
plt.xticks(<span class="hljs-attr">color=hacker_grey)</span>
plt.yticks(<span class="hljs-attr">color=hacker_grey)</span>
<span class="hljs-attr">ax</span> = plt.gca()
ax.set_facecolor(node_black)
ax.spines['bottom'].set_color(hacker_grey)
ax.spines['top'].set_color(node_black)
ax.spines['right'].set_color(node_black)
ax.spines['left'].set_color(hacker_grey)
ax.tick_params(<span class="hljs-attr">axis='x',</span> <span class="hljs-attr">colors=hacker_grey)</span>
ax.tick_params(<span class="hljs-attr">axis='y',</span> <span class="hljs-attr">colors=hacker_grey)</span>
plt.show()
</code></pre>
<p>This is the raw malware image:</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/preproc_1_fixed.png" alt="Image of static noise pattern."></p>
<p>This is the resized and normalized image from our <code>DataLoader</code> that we will feed to the model:</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/preproc_2_fixed.png" alt="Heatmap visualization with varying shades of blue indicating data intensity."></p>
<p>The details can be roughly discerned from the raw image. However, many of the fine details have been lost.</p>
<p>After combining the above code into a single function, we end up with the following code:</p>
<p>Code: python</p>
<pre><code class="lang-python">from torchvision <span class="hljs-built_in">import</span> transforms
from torch.utils.data <span class="hljs-built_in">import</span> DataLoader
from torchvision.datasets <span class="hljs-built_in">import</span> ImageFolder
<span class="hljs-built_in">import</span> os

def load_datasets(base_path, train_batch_size, test_batch_size):
    <span class="hljs-comment"># Define preprocessing transforms</span>
    <span class="hljs-attr">transform</span> = transforms.Compose([
        transforms.Resize((<span class="hljs-number">75</span>, <span class="hljs-number">75</span>)),
        transforms.ToTensor(),
        transforms.Normalize(<span class="hljs-attr">mean=[0.485,</span> <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], <span class="hljs-attr">std=[0.229,</span> <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])
    ])

    <span class="hljs-comment"># Load training and test datasets</span>
    <span class="hljs-attr">train_dataset</span> = ImageFolder(
        <span class="hljs-attr">root=os.path.join(base_path,</span> <span class="hljs-string">"train"</span>),
        <span class="hljs-attr">transform=transform</span>
    )

    <span class="hljs-attr">test_dataset</span> = ImageFolder(
        <span class="hljs-attr">root=os.path.join(base_path,</span> <span class="hljs-string">"test"</span>),
        <span class="hljs-attr">transform=transform</span>
    )

    <span class="hljs-comment"># Create data loaders</span>
    <span class="hljs-attr">train_loader</span> = DataLoader(
        train_dataset,
        <span class="hljs-attr">batch_size=train_batch_size,</span>
        <span class="hljs-attr">shuffle=True,</span>
        <span class="hljs-attr">num_workers=2</span>
    )

    <span class="hljs-attr">test_loader</span> = DataLoader(
        test_dataset,
        <span class="hljs-attr">batch_size=test_batch_size,</span>
        <span class="hljs-attr">shuffle=False,</span>
        <span class="hljs-attr">num_workers=2</span>
    )

    <span class="hljs-attr">n_classes</span> = len(train_dataset.classes)
    return train_loader, test_loader, n_classes
</code></pre>
<p>Note that the function also returns the number of classes in the dataset. As we have mentioned before, the <code>Malimg</code> dataset consists of 25 classes, so we could omit this step and simply assume there are always 25 classes. However, by reading this information dynamically from the data itself, we can use the same code even after making changes to the dataset, either by removing one of the classes or adding new classes to the dataset.</p>
<hr>
<h2 id="the-model">The Model</h2>
<hr>
<p>The heart of any classifier is the model. As discussed previously, we will be using a CNN model. To speed up the training process, we will base our model on a pre-trained version of a well-established CNN called ResNet50.</p>
<hr>
<h3 id="resnet50">ResNet50</h3>
<p>The ResNet family of CNNs was proposed in 2015 in <a href="https://arxiv.org/pdf/1512.03385">this</a> paper. We will use a variant called <code>ResNet50</code>. This model is 50 layers deep, where it got its name, and consists of roughly 23 million parameters. This model is strong in image classification tasks, which perfectly fits our needs for malware classification.</p>
<p>To significantly speed up the training process, we will not start with randomly initialized weights but rather with a pre-trained ResNet50 model. Our code will download pre-trained weights and apply them to our model as a baseline. We will then run our training on the malware image dataset to fine-tune it for our purpose. This approach will save us training time in the magnitude of multiple days or even weeks.</p>
<p>Furthermore, to further speed up the training process, we will <code>freeze</code> the weights of all ResNet layers except for the final one. Thus, during our training process, only the weights of the final layer will change. While this may reduce our classifier&#39;s performance, it will significantly benefit our training time and be a good trade-off for our simple proof-of-concept experiment. We will also adjust the final layer according to our needs. In particular, we may adjust the number of neurons in the final layer and fix the output size to the number of classes in our training data. This results in the following <code>MalwareClassifier</code> class:</p>
<p>Code: python</p>
<pre><code class="lang-python">import torch.nn as nn
import torchvision.models as models

HIDDEN_LAYER_SIZE = <span class="hljs-number">1000</span>

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MalwareClassifier</span>(<span class="hljs-title">nn</span>.<span class="hljs-title">Module</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, n_classes)</span></span>:
        <span class="hljs-keyword">super</span>(MalwareClassifier, <span class="hljs-keyword">self</span>).__init_<span class="hljs-number">_</span>()
        <span class="hljs-comment"># Load pretrained ResNet50</span>
        <span class="hljs-keyword">self</span>.resnet = models.resnet5<span class="hljs-number">0</span>(weights=<span class="hljs-string">'DEFAULT'</span>)

        <span class="hljs-comment"># Freeze ResNet parameters</span>
        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> <span class="hljs-keyword">self</span>.resnet.parameters():
            param.requires_grad = False

        <span class="hljs-comment"># Replace the last fully connected layer</span>
        num_features = <span class="hljs-keyword">self</span>.resnet.fc.in_features
        <span class="hljs-keyword">self</span>.resnet.fc = nn.Sequential(
            nn.Linear(num_features, HIDDEN_LAYER_SIZE),
            nn.ReLU(),
            nn.Linear(HIDDEN_LAYER_SIZE, n_classes)
        )

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, x)</span></span>:
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.resnet(x)
</code></pre>
<p>When initializing the model, we need to specify the number of classes. Since our dataset consists of 25 classes, we can initialize the model like so:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-attr">model</span> = MalwareClassifier(<span class="hljs-number">25</span>)
</code></pre>
<p>However, as discussed in the previous section, the advantage of dynamically setting the number of classes is that we can directly use it from the dataset. By combining the above code with the code from the previous section, we can take the number of classes from the dataset and initialize the model accordingly:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-attr">DATA_PATH</span> = <span class="hljs-string">"./newdata/"</span>
<span class="hljs-attr">TRAINING_BATCH_SIZE</span> = <span class="hljs-number">1024</span>
<span class="hljs-attr">TEST_BATCH_SIZE</span> = <span class="hljs-number">1024</span>

<span class="hljs-comment"># Load datasets</span>
train_loader, test_loader, <span class="hljs-attr">n_classes</span> = load_datasets(DATA_PATH, TRAINING_BATCH_SIZE, TEST_BATCH_SIZE)

<span class="hljs-comment"># Initialize model</span>
<span class="hljs-attr">model</span> = MalwareClassifier(n_classes)
</code></pre>
<hr>
<h2 id="training-and-evaluation-malware-image-classification-">Training and Evaluation (Malware Image Classification)</h2>
<hr>
<p>After loading the datasets and initializing the model, let&#39;s finally discuss model training and evaluation to see how well our model performs.</p>
<hr>
<h3 id="training">Training</h3>
<p>Let us define a training function that takes a model, a training loader, and the number of epochs. We will then specify the loss function as <code>CrossEntropyLoss</code> and use the <code>Adam</code> optimizer. Afterward, we iterate the entire training data for each epoch and run the forward and backward passes. For a refresher on <code>backpropagation</code> and <code>gradient descent</code>, check out the <a href="https://academy.hackthebox.com/module/details/290">Fundamentals of AI</a> module.</p>
<p>The final training function looks like this:</p>
<p>Code: python</p>
<pre><code class="lang-python">import torch
import <span class="hljs-built_in">time</span>

def train(model, train_loader, n_epochs, <span class="hljs-built_in">verbose</span>=False):
    model.train()
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())

    training_data = {<span class="hljs-string">"accuracy"</span>: [], <span class="hljs-string">"loss"</span>: []}

    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_epochs):
        running_loss = <span class="hljs-number">0</span>
        n_total = <span class="hljs-number">0</span>
        n_correct = <span class="hljs-number">0</span>
        checkpoint = <span class="hljs-built_in">time</span>.<span class="hljs-built_in">time</span>() * <span class="hljs-number">1000</span>

        <span class="hljs-keyword">for</span> inputs, <span class="hljs-built_in">labels</span> <span class="hljs-keyword">in</span> train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, <span class="hljs-built_in">labels</span>)
            loss.backward()
            optimizer.<span class="hljs-keyword">step</span>()

            <span class="hljs-symbol">_</span>, predicted = outputs.<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>)
            n_total += <span class="hljs-built_in">labels</span>.size(<span class="hljs-number">0</span>)
            n_correct += predicted.eq(<span class="hljs-built_in">labels</span>).<span class="hljs-built_in">sum</span>().item()
            running_loss += loss.item()

        epoch_loss = running_loss / len(train_loader)
        epoch_duration = int(<span class="hljs-built_in">time</span>.<span class="hljs-built_in">time</span>() * <span class="hljs-number">1000</span> - checkpoint)
        epoch_accuracy = compute_accuracy(n_correct, n_total)

        training_data[<span class="hljs-string">"accuracy"</span>].<span class="hljs-built_in">append</span>(epoch_accuracy)
        training_data[<span class="hljs-string">"loss"</span>].<span class="hljs-built_in">append</span>(epoch_loss)

        <span class="hljs-keyword">if</span> <span class="hljs-built_in">verbose</span>:
            <span class="hljs-built_in">print</span>(f<span class="hljs-string">"[i] Epoch {epoch+1} of {n_epochs}: Acc: {epoch_accuracy:.2f}% Loss: {epoch_loss:.4f} (Took {epoch_duration} ms)."</span>)    

    <span class="hljs-built_in">return</span> training_data
</code></pre>
<p>Note that much of the code within the training function keeps track of information about the training, such as time elapsed, accuracy, and loss.</p>
<p>Additionally, we will define a function to save the trained model to disk for later use:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_model</span><span class="hljs-params">(model, path)</span></span>:
    model_scripted = torch.jit.script(model)
    model_scripted.save(path)
</code></pre>
<hr>
<h3 id="evaluation">Evaluation</h3>
<p>To evaluate the model, we will first define a function that runs the model on a single input and returns the predicted class:</p>
<p>Code: python</p>
<pre><code class="lang-python">def predict(model, test_data):
    model.eval()

    with torch.no_grad():
        output = model(test_data)
        _, predicted = torch.max(output.data, 1)

    <span class="hljs-keyword">return</span> predicted
</code></pre>
<p>We set the model to evaluation mode using the call <code>model.eval()</code> and disable gradient calculation using <code>torch.no_grad()</code>. From there, we can write an evaluation function that iterates over the entire test dataset and evaluates the model&#39;s performance in terms of accuracy:</p>
<p>Code: python</p>
<pre><code class="lang-python">def compute_accuracy(n_correct, n_total):
    <span class="hljs-keyword">return</span> round(100 * n_correct / n_total, 2)


def evaluate(model, test_loader):
    model.eval()

    n_correct = 0
    n_total = 0

    with torch.no_grad():
        <span class="hljs-keyword">for</span> data, <span class="hljs-keyword">target</span> in test_loader:
            predicted = predict(model, data)
            n_total += <span class="hljs-keyword">target</span>.size(0)
            n_correct += (predicted == <span class="hljs-keyword">target</span>).sum().item()

    accuracy = compute_accuracy(n_correct, n_total)  

    <span class="hljs-keyword">return</span> accuracy
</code></pre>
<hr>
<h3 id="plots">Plots</h3>
<p>Lastly, let us define a couple of helper functions that create simple plots for the training accuracy and loss per epoch, respectively:</p>
<p>Code: python</p>
<pre><code class="lang-python">import matplotlib.pyplot as plt

def plot(data, <span class="hljs-built_in">title</span>, <span class="hljs-built_in">label</span>, <span class="hljs-built_in">xlabel</span>, <span class="hljs-built_in">ylabel</span>):
    # HTB Color Palette
    htb_green = <span class="hljs-string">"#9FEF00"</span>
    node_black = <span class="hljs-string">"#141D2B"</span>
    hacker_grey = <span class="hljs-string">"#A4B1CD"</span>

    # plot
    plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>), facecolor=node_black)
    plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, len(data)+<span class="hljs-number">1</span>), data, <span class="hljs-built_in">label</span>=<span class="hljs-built_in">label</span>, <span class="hljs-built_in">color</span>=htb_green)
    plt.<span class="hljs-built_in">title</span>(<span class="hljs-built_in">title</span>, <span class="hljs-built_in">color</span>=htb_green)
    plt.<span class="hljs-built_in">xlabel</span>(<span class="hljs-built_in">xlabel</span>, <span class="hljs-built_in">color</span>=htb_green)
    plt.<span class="hljs-built_in">ylabel</span>(<span class="hljs-built_in">ylabel</span>, <span class="hljs-built_in">color</span>=htb_green)
    plt.xticks(<span class="hljs-built_in">color</span>=hacker_grey)
    plt.yticks(<span class="hljs-built_in">color</span>=hacker_grey)
    ax = plt.gca()
    ax.set_facecolor(node_black)
    ax.spines['bottom'].set_color(hacker_grey)
    ax.spines['top'].set_color(node_black)
    ax.spines['right'].set_color(node_black)
    ax.spines['left'].set_color(hacker_grey)

    <span class="hljs-built_in">legend</span> = plt.<span class="hljs-built_in">legend</span>(facecolor=node_black, edgecolor=hacker_grey, fontsize=<span class="hljs-number">10</span>)
    plt.<span class="hljs-built_in">setp</span>(<span class="hljs-built_in">legend</span>.get_texts(), <span class="hljs-built_in">color</span>=htb_green)

    plt.<span class="hljs-built_in">show</span>()

def plot_training_accuracy(training_data):
    plot(training_data['accuracy'], <span class="hljs-string">"Training Accuracy"</span>, <span class="hljs-string">"Accuracy"</span>, <span class="hljs-string">"Epoch"</span>, <span class="hljs-string">"Accuracy (%)"</span>)

def plot_training_loss(training_data):
    plot(training_data['loss'], <span class="hljs-string">"Training Loss"</span>, <span class="hljs-string">"Loss"</span>, <span class="hljs-string">"Epoch"</span>, <span class="hljs-string">"Loss"</span>)
</code></pre>
<hr>
<h3 id="running-the-code">Running the Code</h3>
<p>After defining all helper functions, we can write a script that defines all parameters and runs the helper functions to load the data, initialize the model, train the model, save the model, and finally evaluate the model:</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-comment"># data parameters</span>
<span class="hljs-attr">DATA_PATH</span> = <span class="hljs-string">"./newdata/"</span>

<span class="hljs-comment"># training parameters</span>
<span class="hljs-attr">N_EPOCHS</span> = <span class="hljs-number">10</span>
<span class="hljs-attr">TRAINING_BATCH_SIZE</span> = <span class="hljs-number">512</span>
<span class="hljs-attr">TEST_BATCH_SIZE</span> = <span class="hljs-number">1024</span>

<span class="hljs-comment"># model parameters</span>
<span class="hljs-attr">HIDDEN_LAYER_SIZE</span> = <span class="hljs-number">1000</span>
<span class="hljs-attr">MODEL_FILE</span> = <span class="hljs-string">"malware_classifier.pth"</span>


<span class="hljs-comment"># Load datasets</span>
train_loader, test_loader, <span class="hljs-attr">n_classes</span> = load_datasets(DATA_PATH, TRAINING_BATCH_SIZE, TEST_BATCH_SIZE)

<span class="hljs-comment"># Initialize model</span>
<span class="hljs-attr">model</span> = MalwareClassifier(n_classes)

<span class="hljs-comment"># Train model</span>
print(<span class="hljs-string">"[i] Starting Training..."</span>)  
<span class="hljs-attr">training_information</span> = train(model, train_loader, N_EPOCHS, <span class="hljs-attr">verbose=True)</span>

<span class="hljs-comment"># Save model</span>
save_model(model, MODEL_FILE)

<span class="hljs-comment"># evaluate model</span>
<span class="hljs-attr">accuracy</span> = evaluate(model, test_loader)
print(f<span class="hljs-string">"[i] Inference accuracy: {accuracy}%."</span>)  

<span class="hljs-comment"># Plot training details</span>
plot_training_accuracy(training_information)
plot_training_loss(training_information)
</code></pre>
<p>Running the final code, we can achieve an accuracy of <code>88.54%</code> on the test dataset:</p>
<p>&#x20; Training and Evaluation (Malware Image Classification)</p>
<pre><code class="lang-shell-session">root@htb[/htb]$ python3 main.py

[i] <span class="hljs-symbol">Epoch</span> <span class="hljs-number">1</span> of <span class="hljs-number">10</span>: <span class="hljs-symbol">Acc</span>: <span class="hljs-number">57.09</span><span class="hljs-comment">% Loss: 1.4741 (Took 41128 ms).</span>
[i] <span class="hljs-symbol">Epoch</span> <span class="hljs-number">2</span> of <span class="hljs-number">10</span>: <span class="hljs-symbol">Acc</span>: <span class="hljs-number">85.01</span><span class="hljs-comment">% Loss: 0.4631 (Took 40630 ms).</span>
[i] <span class="hljs-symbol">Epoch</span> <span class="hljs-number">3</span> of <span class="hljs-number">10</span>: <span class="hljs-symbol">Acc</span>: <span class="hljs-number">89.60</span><span class="hljs-comment">% Loss: 0.2880 (Took 39567 ms).</span>
[i] <span class="hljs-symbol">Epoch</span> <span class="hljs-number">4</span> of <span class="hljs-number">10</span>: <span class="hljs-symbol">Acc</span>: <span class="hljs-number">91.88</span><span class="hljs-comment">% Loss: 0.2294 (Took 39464 ms).</span>
[i] <span class="hljs-symbol">Epoch</span> <span class="hljs-number">5</span> of <span class="hljs-number">10</span>: <span class="hljs-symbol">Acc</span>: <span class="hljs-number">92.97</span><span class="hljs-comment">% Loss: 0.2113 (Took 39367 ms).</span>
[i] <span class="hljs-symbol">Epoch</span> <span class="hljs-number">6</span> of <span class="hljs-number">10</span>: <span class="hljs-symbol">Acc</span>: <span class="hljs-number">93.86</span><span class="hljs-comment">% Loss: 0.1744 (Took 39172 ms).</span>
[i] <span class="hljs-symbol">Epoch</span> <span class="hljs-number">7</span> of <span class="hljs-number">10</span>: <span class="hljs-symbol">Acc</span>: <span class="hljs-number">95.13</span><span class="hljs-comment">% Loss: 0.1572 (Took 39804 ms).</span>
[i] <span class="hljs-symbol">Epoch</span> <span class="hljs-number">8</span> of <span class="hljs-number">10</span>: <span class="hljs-symbol">Acc</span>: <span class="hljs-number">94.81</span><span class="hljs-comment">% Loss: 0.1501 (Took 39092 ms).</span>
[i] <span class="hljs-symbol">Epoch</span> <span class="hljs-number">9</span> of <span class="hljs-number">10</span>: <span class="hljs-symbol">Acc</span>: <span class="hljs-number">96.51</span><span class="hljs-comment">% Loss: 0.1188 (Took 39328 ms).</span>
[i] <span class="hljs-symbol">Epoch</span> <span class="hljs-number">10</span> of <span class="hljs-number">10</span>: <span class="hljs-symbol">Acc</span>: <span class="hljs-number">96.26</span><span class="hljs-comment">% Loss: 0.1198 (Took 39125 ms).</span>
[i] <span class="hljs-symbol">Inference</span> accuracy: <span class="hljs-number">88.54</span><span class="hljs-comment">%.</span>
</code></pre>
<p>During the training process, we can observe a steady increase in accuracy up until the final couple of epochs:</p>
<p><img src="https://academy.hackthebox.com/storage/modules/292/train_1_fixed.png" alt="Line graph of training accuracy over epochs, showing an increase from 60% to 95%."></p>
<p>While the final accuracy is not great, it is acceptable, provided our simple training setup. We have tweaked many parameters to favor training time instead of model performance. Keep in mind that the model&#39;s accuracy may vary depending on the random split of the datasets. Additionally, tweaking the parameters affects both training time and model performance. Feel free to play around with all the parameters the script defines to determine their effects.</p>
<hr>
<h2 id="model-evaluation-malware-image-classification-">Model Evaluation (Malware Image Classification)</h2>
<hr>
<p>To evaluate your model, upload it to the evaluation portal running on the Playground VM. If you are not currently using the Playground VM, you can initialize it at the bottom of the page.</p>
<p>If you have the Playground VM running, you can use this Python script to upload your model from Jupyter directly. Once evaluated, if your model meets the required performance criteria, you will receive a flag value. This flag can be used to answer the question or verify the model’s success.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-built_in">import</span> requests
<span class="hljs-built_in">import</span> json

<span class="hljs-comment"># Define the URL of the API endpoint</span>
<span class="hljs-attr">url</span> = <span class="hljs-string">"http://localhost:8002/api/upload"</span>

<span class="hljs-comment"># Path to the model file you want to upload</span>
<span class="hljs-attr">model_file_path</span> = <span class="hljs-string">"malware_classifier.pth"</span>

<span class="hljs-comment"># Open the file in binary mode and send the POST request</span>
<span class="hljs-keyword">with</span> open(model_file_path, <span class="hljs-string">"rb"</span>) as model_file:
    <span class="hljs-attr">files</span> = {<span class="hljs-string">"model"</span>: model_file}
    <span class="hljs-attr">response</span> = requests.post(url, <span class="hljs-attr">files=files)</span>

<span class="hljs-comment"># Pretty print the response from the server</span>
print(json.dumps(response.json(), <span class="hljs-attr">indent=4))</span>
</code></pre>
<p>If you are working from your own machine, ensure you have configured the HTB VPN to connect to the remote VM, and you have spawned it. After connecting, access the model upload portal by navigating to <code>http://&lt;VM-IP&gt;:8002/</code> in your browser, and then upload your model.</p>
<p>Note: Training time for a single epoch in the Playground environment may take up to 10 minutes. Three epochs should be sufficient to reach the required accuracy. Evaluating an uploaded model may take up to two minutes. Training time on your own system should be much faster, depending on your hardware.</p>
<hr>
<h2 id="skills-assessment">Skills Assessment</h2>
<hr>
<p>The <code>IMDB dataset</code> introduced by Maas et al. (2011) provides a collection of movie reviews extracted from the Internet Movie Database, annotated for <code>sentiment analysis</code>. It includes 50,000 reviews split evenly into training and test sets, and its carefully curated mixture of positive and negative examples allows researchers to benchmark and improve various natural language processing techniques. The <code>IMDB dataset</code> has influenced subsequent work in developing vector-based word representations and remains a popular baseline resource for evaluating classification performance and model architectures in sentiment classification tasks (<a href="http://www.aclweb.org/anthology/P11-1015">Maas et al., 2011</a>).</p>
<p>Your goal is to train a model that can predict whether a movie review is positive (<code>1</code>) or negative (<code>0</code>). You can download the dataset from the question, or <a href="https://academy.hackthebox.com/storage/modules/292/skills_assessment_data.zip">from here</a>.</p>
<p>Out of interest, these exact same techniques can be applied into things such as text moderation for instance.</p>
<hr>
<p>To evaluate your model, upload it to the evaluation portal running on the Playground VM. If you are not currently using the Playground VM, you can initialize it at the bottom of the page.</p>
<p>If you have the Playground VM running, you can use this Python script to upload your model from Jupyter directly. Once evaluated, if your model meets the required performance criteria, you will receive a flag value. This flag can be used to answer the question or verify the model’s success.</p>
<p>Code: python</p>
<pre><code class="lang-python"><span class="hljs-built_in">import</span> requests
<span class="hljs-built_in">import</span> json

<span class="hljs-comment"># Define the URL of the API endpoint</span>
<span class="hljs-attr">url</span> = <span class="hljs-string">"http://localhost:5000/api/upload"</span>

<span class="hljs-comment"># Path to the model file you want to upload</span>
<span class="hljs-attr">model_file_path</span> = <span class="hljs-string">"skills_assessment.joblib"</span>

<span class="hljs-comment"># Open the file in binary mode and send the POST request</span>
<span class="hljs-keyword">with</span> open(model_file_path, <span class="hljs-string">"rb"</span>) as model_file:
    <span class="hljs-attr">files</span> = {<span class="hljs-string">"model"</span>: model_file}
    <span class="hljs-attr">response</span> = requests.post(url, <span class="hljs-attr">files=files)</span>

<span class="hljs-comment"># Pretty print the response from the server</span>
print(json.dumps(response.json(), <span class="hljs-attr">indent=4))</span>
</code></pre>
<p>If you are working from your own machine, ensure you have configured the HTB VPN to connect to the remote VM and spawned it. After connecting, access the model upload portal by navigating to <code>http://VM-IP:5000/</code> in your browser and then uploading your model.</p>
<hr>
